{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVIi8VqQmDiX"
      },
      "source": [
        "# **SETUP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fW-S3vnmBR2"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thkmr3cIgUUf",
        "outputId": "74ac5b71-e379-4c6d-af86-ed3402a231ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-agNV-qKoU",
        "outputId": "3af77def-78bc-40eb-952e-93ebe2614293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adabound\n",
            "  Downloading adabound-0.0.5-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabound) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (4.1.1)\n",
            "Installing collected packages: adabound\n",
            "Successfully installed adabound-0.0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.96-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Collecting botocore<1.28.0,>=1.27.96\n",
            "  Downloading botocore-1.27.96-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 51.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.96->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.96->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.96 botocore-1.27.96 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install adabound\n",
        "!pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JOY16t1YdL29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import yaml\n",
        "import random\n",
        "import spacy\n",
        "import re\n",
        "import json\n",
        "import operator\n",
        "import time\n",
        "import adabound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LMn5SgbMnHLD"
      },
      "outputs": [],
      "source": [
        "from xml.etree.ElementTree import parse\n",
        "from pytorch_pretrained_bert import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eAb1kCdVmeJc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import init\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFizI8b4lx7n"
      },
      "source": [
        "### **Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vh0WA3QwliOE"
      },
      "outputs": [],
      "source": [
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "ASPECT = '<aspect>'\n",
        "\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "ASPECT_INDEX = 2\n",
        "\n",
        "INF = 1e9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VR_mYQnW6Y"
      },
      "source": [
        "# **CLASSES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeyPMH8aoLds"
      },
      "source": [
        "### **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4ClXbYaUdL3O"
      },
      "outputs": [],
      "source": [
        "class ABSADataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, input_list):\n",
        "        super(ABSADataset, self).__init__()\n",
        "        data = np.load(path)\n",
        "        self.data = {}\n",
        "        for key, value in data.items():\n",
        "            self.data[key] = torch.tensor(value).long()\n",
        "        self.len = self.data['label'].size(0)\n",
        "        self.input_list = input_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return_value = []\n",
        "        for input in self.input_list:\n",
        "            return_value.append(self.data[input][index])\n",
        "        return_value.append(self.data['label'][index])\n",
        "        return return_value\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TI3e2ErfdL2_"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self._count_dict = dict()\n",
        "        self._predefined_list = [PAD, UNK, ASPECT]\n",
        "\n",
        "    def add(self, word):\n",
        "        if word in self._count_dict:\n",
        "            self._count_dict[word] += 1\n",
        "        else:\n",
        "            self._count_dict[word] = 1\n",
        "\n",
        "    def add_list(self, words):\n",
        "        for word in words:\n",
        "            self.add(word)\n",
        "\n",
        "    def get_vocab(self, max_size=None, min_freq=0):\n",
        "        # \n",
        "        sorted_words = sorted(self._count_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "        word2index = {}\n",
        "        for word in self._predefined_list:\n",
        "            word2index[word] = len(word2index)\n",
        "        for word, freq in sorted_words:\n",
        "            if word in word2index:\n",
        "                continue\n",
        "            if (max_size is not None and len(word2index) >= max_size) or freq < min_freq:\n",
        "                word2index[word] = word2index[UNK]\n",
        "            else:\n",
        "                word2index[word] = len(word2index)\n",
        "        index2word = {}\n",
        "        index2word[word2index[UNK]] = UNK\n",
        "        for word, index in word2index.items():\n",
        "            if index == word2index[UNK]:\n",
        "                continue\n",
        "            else:\n",
        "                index2word[index] = word\n",
        "        return word2index, index2word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6GHzgVToQtT"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G8tMkZaYdL3L"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    The base class of attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout):\n",
        "        super(Attention, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, query_size) or FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        value: FloatTensor (batch_size, time_step, hidden_size)\n",
        "        mask: ByteTensor (batch_size, time_step) or ByteTensor (batch_size, num_queries, time_step)\n",
        "        \"\"\"\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key) # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        output = weights.matmul(value)\n",
        "        if single_query:\n",
        "            output = output.squeeze(1)\n",
        "        return output\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        raise NotImplementedError('Attention score method is not implemented.')\n",
        "\n",
        "    def _weights_normalize(self, score, mask):\n",
        "        if not mask is None:\n",
        "            score = score.masked_fill(mask == 0, -INF)\n",
        "        weights = F.softmax(score, dim=-1)\n",
        "        return weights\n",
        "\n",
        "    def get_attention_weights(self, query, key, mask=None):\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key)  # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        if single_query:\n",
        "            weights = weights.squeeze(1)\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mr96dasjdL3M"
      },
      "outputs": [],
      "source": [
        "class BilinearAttention(Attention):\n",
        "\n",
        "    def __init__(self, query_size, key_size, dropout=0):\n",
        "        super(BilinearAttention, self).__init__(dropout)\n",
        "        self.weights = nn.Parameter(torch.FloatTensor(query_size, key_size))\n",
        "        init.xavier_uniform_(self.weights)\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        \"\"\"\n",
        "        score = query.matmul(self.weights).matmul(key.transpose(1, 2))\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kD2EgGuhdL3N"
      },
      "outputs": [],
      "source": [
        "class Bert(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, bert_size, dropout, num_categories):\n",
        "        super(Bert, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.bert_size = bert_size\n",
        "        # self.aspect_transform = nn.Sequential(\n",
        "        #     nn.Linear(bert_size, capsule_size),\n",
        "        #     nn.Dropout(dropout)\n",
        "        # )\n",
        "        # self.sentence_transform = nn.Sequential(\n",
        "        #     nn.Linear(bert_size, capsule_size),\n",
        "        #     nn.Dropout(dropout)\n",
        "        # )\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dense = nn.Linear(bert_size, num_categories)\n",
        "\n",
        "\n",
        "    def forward(self, bert_token, bert_segment):\n",
        "        # BERT encoding\n",
        "        _, pooled_layout = self.bert(bert_token, bert_segment, output_all_encoded_layers=False)\n",
        "        pooled_layout = self.dropout(pooled_layout)\n",
        "        logits = self.dense(pooled_layout)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zUocDDn_J8"
      },
      "source": [
        "# **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Qibh7tV9dL3B"
      },
      "outputs": [],
      "source": [
        "def parse_sentence_term(path, lowercase=False):\n",
        "    # parse each sentence into a tree by built-in xml function\n",
        "    tree = parse(path)\n",
        "    \n",
        "    # from here down parse each sentence to \n",
        "    # '[text], [term], [polarity], [from], [to]' with '_split_' inbetween,\n",
        "    # then append to data list. \n",
        "    sentences = tree.getroot()\n",
        "    data = []\n",
        "    split_char = '__split__'\n",
        "    for sentence in sentences:\n",
        "        text = sentence.find('text')\n",
        "        if text is None:\n",
        "            continue\n",
        "        text = text.text\n",
        "        if lowercase:\n",
        "            text = text.lower()\n",
        "        aspectTerms = sentence.find('aspectTerms')\n",
        "        if aspectTerms is None:\n",
        "            continue\n",
        "        for aspectTerm in aspectTerms:\n",
        "            term = aspectTerm.get('term')\n",
        "            if lowercase:\n",
        "                term = term.lower()\n",
        "            polarity = aspectTerm.get('polarity')\n",
        "            start = aspectTerm.get('from')\n",
        "            end = aspectTerm.get('to')\n",
        "            piece = text + split_char + term + split_char + polarity + split_char + start + split_char + end\n",
        "            data.append(piece)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yXdUqmP3dL3D"
      },
      "outputs": [],
      "source": [
        "def category_filter(data, remove_list):\n",
        "    # remove conflicts, only allows polarity 'positive', 'neutral', 'negative'\n",
        "    remove_set = set(remove_list)\n",
        "    filtered_data = []\n",
        "    for text in data:\n",
        "        if not text.split('__split__')[2] in remove_set:\n",
        "            filtered_data.append(text)\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DndCoFiRnduh"
      },
      "outputs": [],
      "source": [
        "def check(x):\n",
        "    return len(x) >= 1 and not x.isspace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nxke1zzhne82"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
        "    return list(filter(check, tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yNavxTnmngNP"
      },
      "outputs": [],
      "source": [
        "def build_vocab(data, max_size, min_freq):\n",
        "    if max_size == 'None':\n",
        "        max_size = None\n",
        "    vocab = Vocab()\n",
        "    for piece in data:\n",
        "        text = piece.split('__split__')[0]\n",
        "        text = tokenizer(text)\n",
        "        vocab.add_list(text)\n",
        "    return vocab.get_vocab(max_size=max_size, min_freq=min_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JIdJFNQvdL3F"
      },
      "outputs": [],
      "source": [
        "def save_term_data(data, word2index, path):\n",
        "    dirname = os.path.dirname(path)\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    sentence = []\n",
        "    aspect = []\n",
        "    label = []\n",
        "    context = []\n",
        "    bert_token = []\n",
        "    bert_segment = []\n",
        "    td_left = []\n",
        "    td_right = []\n",
        "    f = lambda x: word2index[x] if x in word2index else word2index[UNK]\n",
        "    g = lambda x: list(map(f, tokenizer(x)))\n",
        "    d = {\n",
        "        'positive': 0,\n",
        "        'negative': 1,\n",
        "        'neutral': 2,\n",
        "        'conflict': 3\n",
        "    }\n",
        "    for piece in data:\n",
        "        text, term, polarity, start, end = piece.split('__split__')\n",
        "        start, end = int(start), int(end)\n",
        "        assert text[start: end] == term\n",
        "        # sentence appends tokenizer of text\n",
        "        sentence.append(g(text))\n",
        "        # aspect appends tokenizer of term\n",
        "        aspect.append(g(term))\n",
        "        # label appends index of polarity (based on d)\n",
        "        label.append(d[polarity])\n",
        "        # left extracts text to left of term\n",
        "        left_part = g(text[:start])\n",
        "        # right extracts text to right of term\n",
        "        right_part = g(text[end:])\n",
        "        # masking the term, show only text without term\n",
        "        context.append(left_part + [ASPECT_INDEX] + right_part)\n",
        "        bert_sentence = bert_tokenizer.tokenize(text)\n",
        "        bert_aspect = bert_tokenizer.tokenize(term)\n",
        "        # appends bert_text, bert_sentence, bert_aspect to token\n",
        "        bert_token.append(bert_tokenizer.convert_tokens_to_ids(['[CLS]'] + bert_sentence + ['[SEP]'] + bert_aspect + ['[SEP]']))\n",
        "        bert_segment.append([0] * (len(bert_sentence) + 2) + [1] * (len(bert_aspect) + 1))\n",
        "        # td left appends the text from 0 to end of term\n",
        "        td_left.append(g(text[:end]))\n",
        "        # td right appends the text from start of term to end of sentence\n",
        "        td_right.append(g(text[start:])[::-1])\n",
        "        assert len(bert_token[-1]) == len(bert_segment[-1])\n",
        "\n",
        "    max_length = lambda x: max([len(y) for y in x])\n",
        "    sentence_max_len = max_length(sentence)\n",
        "    aspect_max_len = max_length(aspect)\n",
        "    context_max_len = max_length(context)\n",
        "    bert_max_len = max_length(bert_token)\n",
        "    td_left_max_len = max_length(td_left)\n",
        "    td_right_max_len = max_length(td_right)\n",
        "    num = len(data)\n",
        "    for i in range(num):\n",
        "        # pads each list\n",
        "        sentence[i].extend([0] * (sentence_max_len - len(sentence[i])))\n",
        "        aspect[i].extend([0] * (aspect_max_len - len(aspect[i])))\n",
        "        context[i].extend([0] * (context_max_len - len(context[i])))\n",
        "        bert_token[i].extend([0] * (bert_max_len - len(bert_token[i])))\n",
        "        bert_segment[i].extend([0] * (bert_max_len - len(bert_segment[i])))\n",
        "        td_left[i].extend([0] * (td_left_max_len - len(td_left[i])))\n",
        "        td_right[i].extend([0] * (td_right_max_len - len(td_right[i])))\n",
        "    sentence = np.asarray(sentence, dtype=np.int32)\n",
        "    aspect = np.asarray(aspect, dtype=np.int32)\n",
        "    label = np.asarray(label, dtype=np.int32)\n",
        "    context = np.asarray(context, dtype=np.int32)\n",
        "    bert_token = np.asarray(bert_token, dtype=np.int32)\n",
        "    bert_segment = np.asarray(bert_segment, dtype=np.int32)\n",
        "    td_left = np.asarray(td_left, dtype=np.int32)\n",
        "    td_right = np.asarray(td_right, dtype=np.int32)\n",
        "    np.savez(path, sentence=sentence, aspect=aspect, label=label, context=context, bert_token=bert_token, bert_segment=bert_segment,\n",
        "             td_left=td_left, td_right=td_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a9mXiH6SdL3I"
      },
      "outputs": [],
      "source": [
        "def load_sentiment_matrix(glove_path, sentiment_path):\n",
        "    # load hardcoded sentiments and add to vector analysis\n",
        "    sentiment_matrix = np.zeros((3, 300), dtype=np.float32)\n",
        "    sd = json.load(open(sentiment_path, 'r', encoding='utf-8'))\n",
        "    sd['positive'] = set(sd['positive'])\n",
        "    sd['negative'] = set(sd['negative'])\n",
        "    sd['neutral'] = set(sd['neutral'])\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            word = content[0]\n",
        "            vec = np.array(list(map(float, content[1:])))\n",
        "            if word in sd['positive']:\n",
        "                sentiment_matrix[0] += vec\n",
        "            elif word in sd['negative']:\n",
        "                sentiment_matrix[1] += vec\n",
        "            elif word in sd['neutral']:\n",
        "                sentiment_matrix[2] += vec\n",
        "    # normalization\n",
        "    sentiment_matrix -= sentiment_matrix.mean()\n",
        "    sentiment_matrix = sentiment_matrix / sentiment_matrix.std() * np.sqrt(2.0 / (300.0 + 3.0))\n",
        "    return sentiment_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l_9sUTDrdL3J"
      },
      "outputs": [],
      "source": [
        "def analyze_term(data):\n",
        "    num = len(data)\n",
        "    sentence_lens = []\n",
        "    aspect_lens = []\n",
        "    log = {'total': num}\n",
        "    for piece in data:\n",
        "        text, term, polarity, _, _ = piece.split('__split__')\n",
        "        sentence_lens.append(len(tokenizer(text)))\n",
        "        aspect_lens.append(len(tokenizer(term)))\n",
        "        if not polarity in log:\n",
        "            log[polarity] = 0\n",
        "        log[polarity] += 1\n",
        "    log['sentence_max_len'] = max(sentence_lens)\n",
        "    log['sentence_avg_len'] = sum(sentence_lens) / len(sentence_lens)\n",
        "    log['aspect_max_len'] = max(aspect_lens)\n",
        "    log['aspect_avg_len'] = sum(aspect_lens) / len(aspect_lens)\n",
        "    return log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BHOvLH3wdL3K"
      },
      "outputs": [],
      "source": [
        "def sentence_clip(sentence):\n",
        "    mask = (sentence != PAD_INDEX)\n",
        "    sentence_lens = mask.long().sum(dim=1, keepdim=False)\n",
        "    max_len = sentence_lens.max().item()\n",
        "    return sentence[:, :max_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xA0qo61ydL3K"
      },
      "outputs": [],
      "source": [
        "def squash(x, dim=-1):\n",
        "    squared = torch.sum(x * x, dim=dim, keepdim=True)\n",
        "    scale = torch.sqrt(squared) / (1.0 + squared)\n",
        "    return scale * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OpOafbYKdL3P"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    base_path = os.path.join(config['base_path'])\n",
        "    log_path = os.path.join(base_path, 'log/log.yml')\n",
        "    log = yaml.safe_load(open(log_path))\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model = Bert(\n",
        "        bert=bert,\n",
        "        bert_size=config2['bert_size'],\n",
        "        dropout=config2['dropout'],\n",
        "        num_categories=log['num_categories']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v6MxubyGdL3P"
      },
      "outputs": [],
      "source": [
        "def make_term_data():\n",
        "    base_path = config['base_path']\n",
        "    train_path = os.path.join(base_path, 'processed/train.npz')\n",
        "    val_path = os.path.join(base_path, 'processed/val.npz')\n",
        "    train_data = ABSADataset(train_path, ['bert_token', 'bert_segment'])\n",
        "    val_data = ABSADataset(val_path, ['bert_token', 'bert_segment'])\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_term_test_data(config):\n",
        "    base_path = config['base_path']\n",
        "    test_path = os.path.join(base_path, 'processed/test.npz')\n",
        "    test_data = ABSADataset(test_path, ['bert_token', 'bert_segment'])\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return test_loader"
      ],
      "metadata": {
        "id": "My00r6pHROw2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pMlnUPFBdL3Q"
      },
      "outputs": [],
      "source": [
        "def make_optimizer(model):\n",
        "    lr = config2['learning_rate']\n",
        "    weight_decay = config2['weight_decay']\n",
        "    opt = {\n",
        "        'sgd': optim.SGD,\n",
        "        'adadelta': optim.Adadelta,\n",
        "        'adam': optim.Adam,\n",
        "        'adamax': optim.Adamax,\n",
        "        'adagrad': optim.Adagrad,\n",
        "        'asgd': optim.ASGD,\n",
        "        'rmsprop': optim.RMSprop,\n",
        "        'adabound': adabound.AdaBound\n",
        "    }\n",
        "    if 'momentum' in config:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay, momentum=config2['momentum'])\n",
        "    else:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IdlmWNmEomRD"
      },
      "outputs": [],
      "source": [
        "def eval(model, data_loader, criterion=None):\n",
        "    total_samples = 0\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label).item() if criterion is not None else 0\n",
        "            total_samples += input0.size(0)\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            total_loss += loss * input0.size(0)\n",
        "    accuracy = correct_samples / total_samples\n",
        "    avg_loss = total_loss / total_samples\n",
        "    if criterion is not None:\n",
        "        return accuracy, avg_loss\n",
        "    else:\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zAbKjs4wjARE"
      },
      "outputs": [],
      "source": [
        "def load_glove(path, vocab_size, word2index):\n",
        "    if not os.path.isfile(path):\n",
        "        raise IOError('Not a file', path)\n",
        "    glove = np.random.uniform(-0.01, 0.01, [vocab_size, 300])\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            if content[0] in word2index:\n",
        "                glove[word2index[content[0]]] = np.array(list(map(float, content[1:])))\n",
        "    glove[PAD_INDEX, :] = 0\n",
        "    return glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fhYTiEFedL3U"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "    # parse data into list\n",
        "    train_data = parse_sentence_term(config['raw_train_path'], lowercase=config['lowercase'])\n",
        "    val_data = parse_sentence_term(config['raw_val_path'], lowercase=config['lowercase'])\n",
        "    test_data = parse_sentence_term(config['raw_test_path'], lowercase=config['lowercase'])\n",
        "    # filter conflicts\n",
        "    remove_list = ['conflict']\n",
        "    train_data = category_filter(train_data, remove_list)\n",
        "    val_data = category_filter(val_data, remove_list)\n",
        "    test_data = category_filter(test_data, remove_list)\n",
        "    # get the word2index and index2word of the parsed data\n",
        "    word2index, index2word = build_vocab(train_data, max_size=config['max_vocab_size'], min_freq=config['min_vocab_freq'])\n",
        "\n",
        "    # create path for the processed data\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'processed')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'processed'))\n",
        "    \n",
        "          \n",
        "    save_term_data(train_data, word2index, os.path.join(config[\"base_path\"], 'processed/train.npz'))\n",
        "    save_term_data(val_data, word2index, os.path.join(config[\"base_path\"], 'processed/val.npz'))\n",
        "    save_term_data(test_data, word2index, os.path.join(config[\"base_path\"], 'processed/test.npz'))\n",
        "\n",
        "    glove = load_glove(config['glove_path'], len(index2word), word2index)\n",
        "\n",
        "    sentiment_matrix = load_sentiment_matrix(config['glove_path'], config['sentiment_path'])\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/glove.npy'), glove)\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/sentiment_matrix.npy'), sentiment_matrix)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/word2index.pickle'), 'wb') as handle:\n",
        "        pickle.dump(word2index, handle)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/index2word.pickle'), 'wb') as handle:\n",
        "        pickle.dump(index2word, handle)\n",
        "    analyze = analyze_term\n",
        "    log = {\n",
        "        'vocab_size': len(index2word),\n",
        "        'oov_size': len(word2index) - len(index2word),\n",
        "        'train_data': analyze(train_data),\n",
        "        'val_data': analyze(val_data),\n",
        "        'test_data': analyze(test_data),\n",
        "        'num_categories': 3\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'log')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'log'))\n",
        "    with open(os.path.join(config[\"base_path\"], 'log/log.yml'), 'w') as handle:\n",
        "        yaml.safe_dump(log, handle, encoding='utf-8', allow_unicode=True, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BQS3yFtDdL3Q"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    train_loader, val_loader = make_term_data()\n",
        "    global model\n",
        "    model = model.cuda()\n",
        "    base_path = config['base_path']\n",
        "    model_path = os.path.join(base_path, 'bert_models/%s.pth' % \"bert_capsnet\")\n",
        "    if not os.path.exists(os.path.dirname(model_path)):\n",
        "        os.makedirs(os.path.dirname(model_path))\n",
        "    with open(os.path.join(base_path, 'processed/index2word.pickle'), 'rb') as handle:\n",
        "        index2word = pickle.load(handle)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = make_optimizer(model)\n",
        "    max_val_accuracy = 0\n",
        "    min_val_loss = 100\n",
        "    global_step = 0\n",
        "    \n",
        "    for epoch in range(config2['num_epoches']):\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        correct_samples = 0\n",
        "        start = time.time()\n",
        "        for i, data in enumerate(train_loader):\n",
        "            global_step += 1\n",
        "            model.train()\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label)\n",
        "            batch_size = input0.size(0)\n",
        "            total_loss += batch_size * loss.item()\n",
        "            total_samples += batch_size\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "            if i % 10 == 0 and i > 0:\n",
        "                train_loss = total_loss / total_samples\n",
        "                train_accuracy = correct_samples / total_samples\n",
        "                total_loss = 0\n",
        "                total_samples = 0\n",
        "                correct_samples = 0\n",
        "                val_accuracy, val_loss = eval(model, val_loader, criterion)\n",
        "                print('[epoch %2d] [step %3d] train_loss: %.4f train_acc: %.4f val_loss: %.4f val_acc: %.4f'\n",
        "                      % (epoch, i, train_loss, train_accuracy, val_loss, val_accuracy))\n",
        "                if val_accuracy > max_val_accuracy:\n",
        "                    max_val_accuracy = val_accuracy\n",
        "                    # torch.save(aspect_term_model.state_dict(), model_path)\n",
        "                if val_loss < min_val_loss:\n",
        "                    min_val_loss = val_loss\n",
        "                    if epoch > 0:\n",
        "                        torch.save(model.state_dict(), model_path)\n",
        "        end = time.time()\n",
        "        print('time: %.4fs' % (end - start))\n",
        "    print('max_val_accuracy:', max_val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_bert_capsule_network(config):\n",
        "    base_path = os.path.join(config['base_path'])\n",
        "    log_path = os.path.join(base_path, 'log/log.yml')\n",
        "    log = yaml.safe_load(open(log_path))\n",
        "    config = config['aspect_term_model'][config['aspect_term_model']['type']]\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model = Bert(\n",
        "        bert=bert,\n",
        "        bert_size=config['bert_size'],\n",
        "        dropout=config['dropout'],\n",
        "        num_categories=log['num_categories']\n",
        "    )\n",
        "    model.load_sentiment(os.path.join(base_path, 'processed/sentiment_matrix.npy'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "5qqjfQ_JQedA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model = make_model()\n",
        "    model = model.cuda()\n",
        "    model_path = os.path.join(config['base_path'], 'bert_models/%s.pth' % config['mode'])\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    \n",
        "    test_loader = make_term_test_data(config)\n",
        "    test_accuracy = eval(model, test_loader)\n",
        "    print('test:\\taccuracy: %.4f' % (test_accuracy))"
      ],
      "metadata": {
        "id": "TjAknl6zQLUi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4rZNufDpQNi"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as9UA-0NtyNS"
      },
      "source": [
        "### **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed8jTmFBnjaQ",
        "outputId": "bd3dd5df-3e2b-42fb-bfad-8b217498f92e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 254551.43B/s]\n"
          ]
        }
      ],
      "source": [
        "url = re.compile('(<url>.*</url>)')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "conAL_dUdL3R"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"base_path\": \"drive/MyDrive/CS4248/MAMS-ATSA\",\n",
        "    \"mode\": \"bert_capsnet\",\n",
        "    \"glove_path\": \"drive/MyDrive/CS4248/glove.42B.300d.txt\",\n",
        "    \"sentiment_path\": \"drive/MyDrive/CS4248/sentiment_dict.json\",\n",
        "    \"max_vocab_size\": None,\n",
        "    \"min_vocab_freq\": 0,\n",
        "    \"lowercase\": True,\n",
        "    'bert_size': 768,\n",
        "    'capsule_size': 300,\n",
        "    'dropout': 0.1,\n",
        "    'optimizer': 'adam',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.00002,\n",
        "    'weight_decay': 0,\n",
        "    'num_epoches': 5,\n",
        "    'gpu': 0\n",
        "    }\n",
        "\n",
        "config[\"raw_train_path\"] = os.path.join(config[\"base_path\"], 'raw/train.xml')\n",
        "config[\"raw_val_path\"] = os.path.join(config[\"base_path\"], 'raw/val.xml')\n",
        "config[\"raw_test_path\"] = os.path.join(config['base_path'], 'raw/test.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "g0XX1iK3owFD"
      },
      "outputs": [],
      "source": [
        "config2 = {\n",
        "    'bert_size': 768,\n",
        "    'capsule_size': 300,\n",
        "    'dropout': 0.1,\n",
        "    'optimizer': 'adam',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.00002,\n",
        "    'weight_decay': 0,\n",
        "    'num_epoches': 5,\n",
        "    'gpu': 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOXozd3t573"
      },
      "source": [
        "### **Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tjQxMzYWpzrt"
      },
      "outputs": [],
      "source": [
        "preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ay3c-MAfdL3W"
      },
      "outputs": [],
      "source": [
        "model = make_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aK0iM2ZZdL3W",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851a9d6e-f3d0-401f-e859-7cecbd5ca8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch  0] [step  10] train_loss: 1.0968 train_acc: 0.4205 val_loss: 1.0928 val_acc: 0.4535\n",
            "[epoch  0] [step  20] train_loss: 1.0681 train_acc: 0.4813 val_loss: 1.0496 val_acc: 0.4535\n",
            "[epoch  0] [step  30] train_loss: 1.0449 train_acc: 0.4750 val_loss: 1.0355 val_acc: 0.4535\n",
            "[epoch  0] [step  40] train_loss: 1.0464 train_acc: 0.4594 val_loss: 0.9831 val_acc: 0.5128\n",
            "[epoch  0] [step  50] train_loss: 0.9916 train_acc: 0.5281 val_loss: 0.9679 val_acc: 0.5113\n",
            "[epoch  0] [step  60] train_loss: 0.9705 train_acc: 0.5094 val_loss: 0.9492 val_acc: 0.5533\n",
            "[epoch  0] [step  70] train_loss: 1.0038 train_acc: 0.5031 val_loss: 0.9882 val_acc: 0.4685\n",
            "[epoch  0] [step  80] train_loss: 0.9475 train_acc: 0.5500 val_loss: 0.9060 val_acc: 0.5796\n",
            "[epoch  0] [step  90] train_loss: 0.8980 train_acc: 0.6031 val_loss: 0.8835 val_acc: 0.5901\n",
            "[epoch  0] [step 100] train_loss: 0.9158 train_acc: 0.5219 val_loss: 0.8701 val_acc: 0.6096\n",
            "[epoch  0] [step 110] train_loss: 0.8996 train_acc: 0.5719 val_loss: 0.8597 val_acc: 0.6044\n",
            "[epoch  0] [step 120] train_loss: 0.8836 train_acc: 0.5625 val_loss: 0.8678 val_acc: 0.6051\n",
            "[epoch  0] [step 130] train_loss: 0.8546 train_acc: 0.6188 val_loss: 0.8489 val_acc: 0.6299\n",
            "[epoch  0] [step 140] train_loss: 0.9213 train_acc: 0.5312 val_loss: 0.8447 val_acc: 0.6224\n",
            "[epoch  0] [step 150] train_loss: 0.9228 train_acc: 0.5437 val_loss: 0.8374 val_acc: 0.6344\n",
            "[epoch  0] [step 160] train_loss: 0.9317 train_acc: 0.5594 val_loss: 0.8374 val_acc: 0.6209\n",
            "[epoch  0] [step 170] train_loss: 0.8772 train_acc: 0.5938 val_loss: 0.8322 val_acc: 0.6269\n",
            "[epoch  0] [step 180] train_loss: 0.8907 train_acc: 0.5875 val_loss: 0.8228 val_acc: 0.6389\n",
            "[epoch  0] [step 190] train_loss: 0.8502 train_acc: 0.5969 val_loss: 0.8396 val_acc: 0.6374\n",
            "[epoch  0] [step 200] train_loss: 0.8101 train_acc: 0.6344 val_loss: 0.8186 val_acc: 0.6321\n",
            "[epoch  0] [step 210] train_loss: 0.8169 train_acc: 0.5969 val_loss: 0.8154 val_acc: 0.6411\n",
            "[epoch  0] [step 220] train_loss: 0.8225 train_acc: 0.6250 val_loss: 0.8417 val_acc: 0.6186\n",
            "[epoch  0] [step 230] train_loss: 0.8664 train_acc: 0.5906 val_loss: 0.8092 val_acc: 0.6464\n",
            "[epoch  0] [step 240] train_loss: 0.8254 train_acc: 0.6656 val_loss: 0.7955 val_acc: 0.6396\n",
            "[epoch  0] [step 250] train_loss: 0.8467 train_acc: 0.6031 val_loss: 0.7891 val_acc: 0.6517\n",
            "[epoch  0] [step 260] train_loss: 0.7997 train_acc: 0.6250 val_loss: 0.7843 val_acc: 0.6667\n",
            "[epoch  0] [step 270] train_loss: 0.7876 train_acc: 0.6531 val_loss: 0.7798 val_acc: 0.6794\n",
            "[epoch  0] [step 280] train_loss: 0.8298 train_acc: 0.6250 val_loss: 0.7890 val_acc: 0.6464\n",
            "[epoch  0] [step 290] train_loss: 0.8292 train_acc: 0.6562 val_loss: 0.7771 val_acc: 0.6757\n",
            "[epoch  0] [step 300] train_loss: 0.8327 train_acc: 0.6000 val_loss: 0.7673 val_acc: 0.6712\n",
            "[epoch  0] [step 310] train_loss: 0.7881 train_acc: 0.6375 val_loss: 0.7670 val_acc: 0.6667\n",
            "[epoch  0] [step 320] train_loss: 0.8047 train_acc: 0.6344 val_loss: 0.7472 val_acc: 0.6922\n",
            "[epoch  0] [step 330] train_loss: 0.7665 train_acc: 0.6469 val_loss: 0.7319 val_acc: 0.6967\n",
            "[epoch  0] [step 340] train_loss: 0.7785 train_acc: 0.6500 val_loss: 0.7445 val_acc: 0.6877\n",
            "time: 458.3646s\n",
            "[epoch  1] [step  10] train_loss: 0.7608 train_acc: 0.6676 val_loss: 0.7576 val_acc: 0.6674\n",
            "[epoch  1] [step  20] train_loss: 0.7116 train_acc: 0.6594 val_loss: 0.7337 val_acc: 0.6824\n",
            "[epoch  1] [step  30] train_loss: 0.7196 train_acc: 0.6594 val_loss: 0.7396 val_acc: 0.6929\n",
            "[epoch  1] [step  40] train_loss: 0.6941 train_acc: 0.7156 val_loss: 0.7256 val_acc: 0.6832\n",
            "[epoch  1] [step  50] train_loss: 0.7172 train_acc: 0.6750 val_loss: 0.7177 val_acc: 0.7020\n",
            "[epoch  1] [step  60] train_loss: 0.6994 train_acc: 0.7063 val_loss: 0.7281 val_acc: 0.6749\n",
            "[epoch  1] [step  70] train_loss: 0.6708 train_acc: 0.6969 val_loss: 0.7078 val_acc: 0.6967\n",
            "[epoch  1] [step  80] train_loss: 0.6922 train_acc: 0.7063 val_loss: 0.7003 val_acc: 0.7020\n",
            "[epoch  1] [step  90] train_loss: 0.6583 train_acc: 0.7000 val_loss: 0.6812 val_acc: 0.7222\n",
            "[epoch  1] [step 100] train_loss: 0.7173 train_acc: 0.6937 val_loss: 0.6615 val_acc: 0.7200\n",
            "[epoch  1] [step 110] train_loss: 0.6811 train_acc: 0.7125 val_loss: 0.6509 val_acc: 0.7275\n",
            "[epoch  1] [step 120] train_loss: 0.6577 train_acc: 0.7250 val_loss: 0.6402 val_acc: 0.7417\n",
            "[epoch  1] [step 130] train_loss: 0.6885 train_acc: 0.7125 val_loss: 0.6291 val_acc: 0.7425\n",
            "[epoch  1] [step 140] train_loss: 0.6636 train_acc: 0.7250 val_loss: 0.6564 val_acc: 0.7267\n",
            "[epoch  1] [step 150] train_loss: 0.6647 train_acc: 0.7219 val_loss: 0.6384 val_acc: 0.7432\n",
            "[epoch  1] [step 160] train_loss: 0.5660 train_acc: 0.7594 val_loss: 0.5912 val_acc: 0.7590\n",
            "[epoch  1] [step 170] train_loss: 0.5873 train_acc: 0.7688 val_loss: 0.5896 val_acc: 0.7538\n",
            "[epoch  1] [step 180] train_loss: 0.6618 train_acc: 0.7344 val_loss: 0.5636 val_acc: 0.7710\n",
            "[epoch  1] [step 190] train_loss: 0.6111 train_acc: 0.7406 val_loss: 0.5960 val_acc: 0.7598\n",
            "[epoch  1] [step 200] train_loss: 0.5635 train_acc: 0.7812 val_loss: 0.5668 val_acc: 0.7703\n",
            "[epoch  1] [step 210] train_loss: 0.5525 train_acc: 0.7937 val_loss: 0.5509 val_acc: 0.7838\n",
            "[epoch  1] [step 220] train_loss: 0.5274 train_acc: 0.7969 val_loss: 0.5697 val_acc: 0.7680\n",
            "[epoch  1] [step 230] train_loss: 0.5792 train_acc: 0.7562 val_loss: 0.5411 val_acc: 0.7853\n",
            "[epoch  1] [step 240] train_loss: 0.4995 train_acc: 0.8031 val_loss: 0.5386 val_acc: 0.7815\n",
            "[epoch  1] [step 250] train_loss: 0.4649 train_acc: 0.8313 val_loss: 0.5595 val_acc: 0.7718\n",
            "[epoch  1] [step 260] train_loss: 0.4957 train_acc: 0.8063 val_loss: 0.5414 val_acc: 0.7845\n",
            "[epoch  1] [step 270] train_loss: 0.5589 train_acc: 0.7844 val_loss: 0.5268 val_acc: 0.7920\n",
            "[epoch  1] [step 280] train_loss: 0.4677 train_acc: 0.8000 val_loss: 0.5279 val_acc: 0.7965\n",
            "[epoch  1] [step 290] train_loss: 0.5024 train_acc: 0.7937 val_loss: 0.5243 val_acc: 0.7950\n",
            "[epoch  1] [step 300] train_loss: 0.4822 train_acc: 0.8063 val_loss: 0.5230 val_acc: 0.7950\n",
            "[epoch  1] [step 310] train_loss: 0.5548 train_acc: 0.7875 val_loss: 0.5186 val_acc: 0.8003\n",
            "[epoch  1] [step 320] train_loss: 0.4627 train_acc: 0.8000 val_loss: 0.5170 val_acc: 0.7935\n",
            "[epoch  1] [step 330] train_loss: 0.5837 train_acc: 0.7781 val_loss: 0.5057 val_acc: 0.7928\n",
            "[epoch  1] [step 340] train_loss: 0.4628 train_acc: 0.8094 val_loss: 0.5118 val_acc: 0.7883\n",
            "time: 499.2754s\n",
            "[epoch  2] [step  10] train_loss: 0.3233 train_acc: 0.8920 val_loss: 0.5162 val_acc: 0.8048\n",
            "[epoch  2] [step  20] train_loss: 0.3779 train_acc: 0.8688 val_loss: 0.5449 val_acc: 0.8071\n",
            "[epoch  2] [step  30] train_loss: 0.3914 train_acc: 0.8781 val_loss: 0.5338 val_acc: 0.7980\n",
            "[epoch  2] [step  40] train_loss: 0.4060 train_acc: 0.8469 val_loss: 0.5138 val_acc: 0.7988\n",
            "[epoch  2] [step  50] train_loss: 0.3895 train_acc: 0.8562 val_loss: 0.5117 val_acc: 0.8078\n",
            "[epoch  2] [step  60] train_loss: 0.3558 train_acc: 0.8719 val_loss: 0.5180 val_acc: 0.8026\n",
            "[epoch  2] [step  70] train_loss: 0.4200 train_acc: 0.8531 val_loss: 0.5044 val_acc: 0.8086\n",
            "[epoch  2] [step  80] train_loss: 0.3613 train_acc: 0.8562 val_loss: 0.5026 val_acc: 0.8086\n",
            "[epoch  2] [step  90] train_loss: 0.2847 train_acc: 0.8781 val_loss: 0.5318 val_acc: 0.7965\n",
            "[epoch  2] [step 100] train_loss: 0.3620 train_acc: 0.8812 val_loss: 0.5321 val_acc: 0.8093\n",
            "[epoch  2] [step 110] train_loss: 0.4366 train_acc: 0.8250 val_loss: 0.5148 val_acc: 0.8086\n",
            "[epoch  2] [step 120] train_loss: 0.3694 train_acc: 0.8625 val_loss: 0.4900 val_acc: 0.8221\n",
            "[epoch  2] [step 130] train_loss: 0.3522 train_acc: 0.8688 val_loss: 0.4993 val_acc: 0.8161\n",
            "[epoch  2] [step 140] train_loss: 0.3465 train_acc: 0.8750 val_loss: 0.5202 val_acc: 0.8041\n",
            "[epoch  2] [step 150] train_loss: 0.3362 train_acc: 0.9000 val_loss: 0.5533 val_acc: 0.7973\n",
            "[epoch  2] [step 160] train_loss: 0.3728 train_acc: 0.8531 val_loss: 0.5402 val_acc: 0.8011\n",
            "[epoch  2] [step 170] train_loss: 0.4160 train_acc: 0.8438 val_loss: 0.4921 val_acc: 0.8161\n",
            "[epoch  2] [step 180] train_loss: 0.3566 train_acc: 0.8656 val_loss: 0.4801 val_acc: 0.8176\n",
            "[epoch  2] [step 190] train_loss: 0.4086 train_acc: 0.8313 val_loss: 0.4761 val_acc: 0.8183\n",
            "[epoch  2] [step 200] train_loss: 0.3426 train_acc: 0.8625 val_loss: 0.4881 val_acc: 0.8191\n",
            "[epoch  2] [step 210] train_loss: 0.3671 train_acc: 0.8531 val_loss: 0.4897 val_acc: 0.8138\n",
            "[epoch  2] [step 220] train_loss: 0.3926 train_acc: 0.8375 val_loss: 0.4799 val_acc: 0.8206\n",
            "[epoch  2] [step 230] train_loss: 0.4046 train_acc: 0.8375 val_loss: 0.4969 val_acc: 0.8116\n",
            "[epoch  2] [step 240] train_loss: 0.3337 train_acc: 0.8531 val_loss: 0.5279 val_acc: 0.8071\n",
            "[epoch  2] [step 250] train_loss: 0.4318 train_acc: 0.8406 val_loss: 0.5060 val_acc: 0.8116\n",
            "[epoch  2] [step 260] train_loss: 0.3411 train_acc: 0.8750 val_loss: 0.5053 val_acc: 0.8056\n",
            "[epoch  2] [step 270] train_loss: 0.3844 train_acc: 0.8562 val_loss: 0.4913 val_acc: 0.8108\n",
            "[epoch  2] [step 280] train_loss: 0.3790 train_acc: 0.8438 val_loss: 0.4965 val_acc: 0.8213\n",
            "[epoch  2] [step 290] train_loss: 0.4357 train_acc: 0.8406 val_loss: 0.4960 val_acc: 0.8161\n",
            "[epoch  2] [step 300] train_loss: 0.2656 train_acc: 0.8875 val_loss: 0.4811 val_acc: 0.8206\n",
            "[epoch  2] [step 310] train_loss: 0.4131 train_acc: 0.8344 val_loss: 0.4905 val_acc: 0.8191\n",
            "[epoch  2] [step 320] train_loss: 0.3213 train_acc: 0.8781 val_loss: 0.4870 val_acc: 0.8243\n",
            "[epoch  2] [step 330] train_loss: 0.4081 train_acc: 0.8469 val_loss: 0.4962 val_acc: 0.8153\n",
            "[epoch  2] [step 340] train_loss: 0.4035 train_acc: 0.8500 val_loss: 0.5252 val_acc: 0.8093\n",
            "time: 477.2693s\n",
            "[epoch  3] [step  10] train_loss: 0.2592 train_acc: 0.9119 val_loss: 0.5093 val_acc: 0.8168\n",
            "[epoch  3] [step  20] train_loss: 0.1871 train_acc: 0.9406 val_loss: 0.5144 val_acc: 0.8251\n",
            "[epoch  3] [step  30] train_loss: 0.2553 train_acc: 0.9250 val_loss: 0.5360 val_acc: 0.8153\n",
            "[epoch  3] [step  40] train_loss: 0.2220 train_acc: 0.9250 val_loss: 0.5341 val_acc: 0.8236\n",
            "[epoch  3] [step  50] train_loss: 0.1819 train_acc: 0.9500 val_loss: 0.5389 val_acc: 0.8266\n",
            "[epoch  3] [step  60] train_loss: 0.2285 train_acc: 0.9313 val_loss: 0.5601 val_acc: 0.8131\n",
            "[epoch  3] [step  70] train_loss: 0.2335 train_acc: 0.9125 val_loss: 0.5419 val_acc: 0.8236\n",
            "[epoch  3] [step  80] train_loss: 0.2661 train_acc: 0.9031 val_loss: 0.5476 val_acc: 0.8101\n",
            "[epoch  3] [step  90] train_loss: 0.2123 train_acc: 0.9094 val_loss: 0.5321 val_acc: 0.8191\n",
            "[epoch  3] [step 100] train_loss: 0.2934 train_acc: 0.9031 val_loss: 0.5251 val_acc: 0.8228\n",
            "[epoch  3] [step 110] train_loss: 0.1686 train_acc: 0.9469 val_loss: 0.5496 val_acc: 0.8198\n",
            "[epoch  3] [step 120] train_loss: 0.2378 train_acc: 0.9187 val_loss: 0.5321 val_acc: 0.8236\n",
            "[epoch  3] [step 130] train_loss: 0.2629 train_acc: 0.9156 val_loss: 0.5412 val_acc: 0.8221\n",
            "[epoch  3] [step 140] train_loss: 0.2038 train_acc: 0.9156 val_loss: 0.5452 val_acc: 0.8251\n",
            "[epoch  3] [step 150] train_loss: 0.2610 train_acc: 0.9062 val_loss: 0.5739 val_acc: 0.8093\n",
            "[epoch  3] [step 160] train_loss: 0.1952 train_acc: 0.9406 val_loss: 0.5494 val_acc: 0.8138\n",
            "[epoch  3] [step 170] train_loss: 0.1909 train_acc: 0.9219 val_loss: 0.5765 val_acc: 0.8093\n",
            "[epoch  3] [step 180] train_loss: 0.2754 train_acc: 0.8969 val_loss: 0.5695 val_acc: 0.8183\n",
            "[epoch  3] [step 190] train_loss: 0.2007 train_acc: 0.9313 val_loss: 0.5837 val_acc: 0.8101\n",
            "[epoch  3] [step 200] train_loss: 0.2453 train_acc: 0.9156 val_loss: 0.5587 val_acc: 0.8228\n",
            "[epoch  3] [step 210] train_loss: 0.2358 train_acc: 0.9062 val_loss: 0.5539 val_acc: 0.8183\n",
            "[epoch  3] [step 220] train_loss: 0.2562 train_acc: 0.9062 val_loss: 0.5496 val_acc: 0.8183\n",
            "[epoch  3] [step 230] train_loss: 0.2350 train_acc: 0.9094 val_loss: 0.5313 val_acc: 0.8191\n",
            "[epoch  3] [step 240] train_loss: 0.2350 train_acc: 0.9250 val_loss: 0.5193 val_acc: 0.8251\n",
            "[epoch  3] [step 250] train_loss: 0.2910 train_acc: 0.8906 val_loss: 0.5357 val_acc: 0.8146\n",
            "[epoch  3] [step 260] train_loss: 0.1929 train_acc: 0.9437 val_loss: 0.5998 val_acc: 0.8018\n",
            "[epoch  3] [step 270] train_loss: 0.2276 train_acc: 0.9219 val_loss: 0.5827 val_acc: 0.8213\n",
            "[epoch  3] [step 280] train_loss: 0.2115 train_acc: 0.9250 val_loss: 0.5733 val_acc: 0.8236\n",
            "[epoch  3] [step 290] train_loss: 0.1907 train_acc: 0.9344 val_loss: 0.5798 val_acc: 0.8176\n",
            "[epoch  3] [step 300] train_loss: 0.2697 train_acc: 0.9156 val_loss: 0.5800 val_acc: 0.8161\n",
            "[epoch  3] [step 310] train_loss: 0.3088 train_acc: 0.8844 val_loss: 0.5721 val_acc: 0.8176\n",
            "[epoch  3] [step 320] train_loss: 0.2864 train_acc: 0.9062 val_loss: 0.5641 val_acc: 0.8116\n",
            "[epoch  3] [step 330] train_loss: 0.2413 train_acc: 0.9062 val_loss: 0.5299 val_acc: 0.8251\n",
            "[epoch  3] [step 340] train_loss: 0.2551 train_acc: 0.8938 val_loss: 0.5860 val_acc: 0.8048\n",
            "time: 472.3462s\n",
            "[epoch  4] [step  10] train_loss: 0.1441 train_acc: 0.9403 val_loss: 0.5638 val_acc: 0.8243\n",
            "[epoch  4] [step  20] train_loss: 0.1139 train_acc: 0.9688 val_loss: 0.5902 val_acc: 0.8251\n",
            "[epoch  4] [step  30] train_loss: 0.1449 train_acc: 0.9563 val_loss: 0.6314 val_acc: 0.8168\n",
            "[epoch  4] [step  40] train_loss: 0.1369 train_acc: 0.9531 val_loss: 0.6069 val_acc: 0.8236\n",
            "[epoch  4] [step  50] train_loss: 0.1340 train_acc: 0.9563 val_loss: 0.6079 val_acc: 0.8266\n",
            "[epoch  4] [step  60] train_loss: 0.0721 train_acc: 0.9750 val_loss: 0.6687 val_acc: 0.8086\n",
            "[epoch  4] [step  70] train_loss: 0.1189 train_acc: 0.9437 val_loss: 0.6379 val_acc: 0.8318\n",
            "[epoch  4] [step  80] train_loss: 0.1508 train_acc: 0.9281 val_loss: 0.6463 val_acc: 0.8296\n",
            "[epoch  4] [step  90] train_loss: 0.2008 train_acc: 0.9500 val_loss: 0.6597 val_acc: 0.8153\n",
            "[epoch  4] [step 100] train_loss: 0.1249 train_acc: 0.9563 val_loss: 0.6091 val_acc: 0.8303\n",
            "[epoch  4] [step 110] train_loss: 0.1539 train_acc: 0.9563 val_loss: 0.6595 val_acc: 0.8123\n",
            "[epoch  4] [step 120] train_loss: 0.1638 train_acc: 0.9437 val_loss: 0.6167 val_acc: 0.8311\n",
            "[epoch  4] [step 130] train_loss: 0.1847 train_acc: 0.9375 val_loss: 0.6293 val_acc: 0.8198\n",
            "[epoch  4] [step 140] train_loss: 0.1554 train_acc: 0.9406 val_loss: 0.5991 val_acc: 0.8281\n",
            "[epoch  4] [step 150] train_loss: 0.0883 train_acc: 0.9719 val_loss: 0.6230 val_acc: 0.8191\n",
            "[epoch  4] [step 160] train_loss: 0.1229 train_acc: 0.9688 val_loss: 0.6285 val_acc: 0.8206\n",
            "[epoch  4] [step 170] train_loss: 0.1389 train_acc: 0.9437 val_loss: 0.6308 val_acc: 0.8213\n",
            "[epoch  4] [step 180] train_loss: 0.2052 train_acc: 0.9375 val_loss: 0.6338 val_acc: 0.8221\n",
            "[epoch  4] [step 190] train_loss: 0.1277 train_acc: 0.9563 val_loss: 0.6515 val_acc: 0.8258\n",
            "[epoch  4] [step 200] train_loss: 0.1508 train_acc: 0.9500 val_loss: 0.6395 val_acc: 0.8191\n",
            "[epoch  4] [step 210] train_loss: 0.1625 train_acc: 0.9406 val_loss: 0.6397 val_acc: 0.8168\n",
            "[epoch  4] [step 220] train_loss: 0.1712 train_acc: 0.9531 val_loss: 0.6265 val_acc: 0.8213\n",
            "[epoch  4] [step 230] train_loss: 0.2061 train_acc: 0.9437 val_loss: 0.6237 val_acc: 0.8236\n",
            "[epoch  4] [step 240] train_loss: 0.1745 train_acc: 0.9344 val_loss: 0.5969 val_acc: 0.8258\n",
            "[epoch  4] [step 250] train_loss: 0.2205 train_acc: 0.9281 val_loss: 0.5996 val_acc: 0.8251\n",
            "[epoch  4] [step 260] train_loss: 0.1376 train_acc: 0.9437 val_loss: 0.6324 val_acc: 0.8236\n",
            "[epoch  4] [step 270] train_loss: 0.1154 train_acc: 0.9594 val_loss: 0.6378 val_acc: 0.8123\n",
            "[epoch  4] [step 280] train_loss: 0.1749 train_acc: 0.9500 val_loss: 0.6445 val_acc: 0.8146\n",
            "[epoch  4] [step 290] train_loss: 0.1142 train_acc: 0.9656 val_loss: 0.6476 val_acc: 0.8213\n",
            "[epoch  4] [step 300] train_loss: 0.1263 train_acc: 0.9625 val_loss: 0.6712 val_acc: 0.8146\n",
            "[epoch  4] [step 310] train_loss: 0.1586 train_acc: 0.9437 val_loss: 0.6498 val_acc: 0.8198\n",
            "[epoch  4] [step 320] train_loss: 0.1516 train_acc: 0.9500 val_loss: 0.6362 val_acc: 0.8296\n",
            "[epoch  4] [step 330] train_loss: 0.1953 train_acc: 0.9344 val_loss: 0.6579 val_acc: 0.8243\n",
            "[epoch  4] [step 340] train_loss: 0.1717 train_acc: 0.9437 val_loss: 0.6422 val_acc: 0.8236\n",
            "time: 473.1416s\n",
            "max_val_accuracy: 0.8318318318318318\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZH08jYT2Uan",
        "outputId": "97437d12-e67e-4115-9f06-7bf35df9747f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test:\taccuracy: 0.8278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3Q05su4i3Wr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('CS4248-project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "acc163ef47be86fb239cdb7a5b440891b3a074f9418fa7049e8ce9b17a74f46c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}