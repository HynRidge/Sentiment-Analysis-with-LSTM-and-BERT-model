{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gzW8kficXIG"
      },
      "source": [
        "## **ACKNOWLEDGEMENT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yx1oACXcrYx"
      },
      "source": [
        "This code is inspired by https://github.com/siat-nlp/MAMS-for-ABSA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVIi8VqQmDiX"
      },
      "source": [
        "## **SETUP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fW-S3vnmBR2"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thkmr3cIgUUf",
        "outputId": "79f83dea-c9e4-4356-dc26-2fc676c52013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-agNV-qKoU",
        "outputId": "3dfe45e4-82a4-4001-f5ab-b90998fc2673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: adabound in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabound) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.26.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.3 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.29.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.3->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.3->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.3->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "!pip install adabound\n",
        "!pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JOY16t1YdL29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import yaml\n",
        "import random\n",
        "import spacy\n",
        "import re\n",
        "import json\n",
        "import operator\n",
        "import time\n",
        "import adabound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LK_5o4_t-zma"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "LMn5SgbMnHLD"
      },
      "outputs": [],
      "source": [
        "from xml.etree.ElementTree import parse\n",
        "from pytorch_pretrained_bert import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "eAb1kCdVmeJc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import init\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFizI8b4lx7n"
      },
      "source": [
        "### **Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "vh0WA3QwliOE"
      },
      "outputs": [],
      "source": [
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "ASPECT = '<aspect>'\n",
        "\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "ASPECT_INDEX = 2\n",
        "\n",
        "INF = 1e9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "Ed8jTmFBnjaQ"
      },
      "outputs": [],
      "source": [
        "url = re.compile('(<url>.*</url>)')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VR_mYQnW6Y"
      },
      "source": [
        "# **CLASSES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeyPMH8aoLds"
      },
      "source": [
        "### **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "4ClXbYaUdL3O"
      },
      "outputs": [],
      "source": [
        "class ABSADataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, input_list):\n",
        "        super(ABSADataset, self).__init__()\n",
        "        data = np.load(path)\n",
        "        self.data = {}\n",
        "        for key, value in data.items():\n",
        "            self.data[key] = torch.tensor(value).long()\n",
        "        self.len = self.data['label'].size(0)\n",
        "        self.input_list = input_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return_value = []\n",
        "        for input in self.input_list:\n",
        "            return_value.append(self.data[input][index])\n",
        "        return_value.append(self.data['label'][index])\n",
        "        return return_value\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "TI3e2ErfdL2_"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self._count_dict = dict()\n",
        "        self._predefined_list = [PAD, UNK, ASPECT]\n",
        "\n",
        "    def add(self, word):\n",
        "        if word in self._count_dict:\n",
        "            self._count_dict[word] += 1\n",
        "        else:\n",
        "            self._count_dict[word] = 1\n",
        "\n",
        "    def add_list(self, words):\n",
        "        for word in words:\n",
        "            self.add(word)\n",
        "\n",
        "    def get_vocab(self, max_size=None, min_freq=0):\n",
        "        # \n",
        "        sorted_words = sorted(self._count_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "        word2index = {}\n",
        "        for word in self._predefined_list:\n",
        "            word2index[word] = len(word2index)\n",
        "        for word, freq in sorted_words:\n",
        "            if word in word2index:\n",
        "                continue\n",
        "            if (max_size is not None and len(word2index) >= max_size) or freq < min_freq:\n",
        "                word2index[word] = word2index[UNK]\n",
        "            else:\n",
        "                word2index[word] = len(word2index)\n",
        "        index2word = {}\n",
        "        index2word[word2index[UNK]] = UNK\n",
        "        for word, index in word2index.items():\n",
        "            if index == word2index[UNK]:\n",
        "                continue\n",
        "            else:\n",
        "                index2word[index] = word\n",
        "        return word2index, index2word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6GHzgVToQtT"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "G8tMkZaYdL3L"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    The base class of attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout):\n",
        "        super(Attention, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, query_size) or FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        value: FloatTensor (batch_size, time_step, hidden_size)\n",
        "        mask: ByteTensor (batch_size, time_step) or ByteTensor (batch_size, num_queries, time_step)\n",
        "        \"\"\"\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key) # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        output = weights.matmul(value)\n",
        "        if single_query:\n",
        "            output = output.squeeze(1)\n",
        "        return output\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        raise NotImplementedError('Attention score method is not implemented.')\n",
        "\n",
        "    def _weights_normalize(self, score, mask):\n",
        "        if not mask is None:\n",
        "            score = score.masked_fill(mask == 0, -INF)\n",
        "        weights = F.softmax(score, dim=-1)\n",
        "        return weights\n",
        "\n",
        "    def get_attention_weights(self, query, key, mask=None):\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key)  # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        if single_query:\n",
        "            weights = weights.squeeze(1)\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "Mr96dasjdL3M"
      },
      "outputs": [],
      "source": [
        "class BilinearAttention(Attention):\n",
        "\n",
        "    def __init__(self, query_size, key_size, dropout=0):\n",
        "        super(BilinearAttention, self).__init__(dropout)\n",
        "        self.weights = nn.Parameter(torch.FloatTensor(query_size, key_size))\n",
        "        init.xavier_uniform_(self.weights)\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        \"\"\"\n",
        "        score = query.matmul(self.weights).matmul(key.transpose(1, 2))\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "FluDi2TjzJP4"
      },
      "outputs": [],
      "source": [
        "class ConcatAttention(Attention):\n",
        "\n",
        "    def __init__(self, query_size, key_size, dropout=0):\n",
        "        super(ConcatAttention, self).__init__(dropout)\n",
        "        self.query_weights = nn.Parameter(torch.Tensor(query_size, 1))\n",
        "        self.key_weights = nn.Parameter(torch.Tensor(key_size, 1))\n",
        "        init.xavier_uniform_(self.query_weights)\n",
        "        init.xavier_uniform_(self.key_weights)\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        \"\"\"\n",
        "        batch_size, num_queries, time_step = query.size(0), query.size(1), key.size(1)\n",
        "        query = query.matmul(self.query_weights).expand(batch_size, num_queries, time_step)\n",
        "        key = key.matmul(self.key_weights).transpose(1, 2).expand(batch_size, num_queries, time_step)\n",
        "        score = query + key\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "kD2EgGuhdL3N"
      },
      "outputs": [],
      "source": [
        "class BertCapsuleNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, bert_size, capsule_size, dropout, num_categories):\n",
        "        super(BertCapsuleNetwork, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.bert_size = bert_size\n",
        "        self.capsule_size = capsule_size\n",
        "        self.aspect_transform = nn.Sequential(\n",
        "            nn.Linear(bert_size, capsule_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.sentence_transform = nn.Sequential(\n",
        "            nn.Linear(bert_size, capsule_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm_attention = ConcatAttention(capsule_size, capsule_size)\n",
        "        self.guide_capsule = nn.Parameter(\n",
        "            torch.Tensor(num_categories, capsule_size)\n",
        "        )\n",
        "        self.guide_weight = nn.Parameter(\n",
        "            torch.Tensor(capsule_size, capsule_size)\n",
        "        )\n",
        "        self.scale = nn.Parameter(torch.tensor(5.0))\n",
        "        self.capsule_projection = nn.Linear(bert_size, bert_size * num_categories)\n",
        "        self.dropout = dropout\n",
        "        self.num_categories = num_categories\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        init.xavier_uniform_(self.guide_capsule)\n",
        "        init.xavier_uniform_(self.guide_weight)\n",
        "\n",
        "    def load_sentiment(self, path):\n",
        "        sentiment = np.load(path)\n",
        "        e1 = np.mean(sentiment)\n",
        "        d1 = np.std(sentiment)\n",
        "        e2 = 0\n",
        "        d2 = np.sqrt(2.0 / (sentiment.shape[0] + sentiment.shape[1]))\n",
        "        sentiment = (sentiment - e1) / d1 * d2 + e2\n",
        "        self.guide_capsule.data.copy_(torch.tensor(sentiment))\n",
        "\n",
        "    def forward(self, bert_token, bert_segment):\n",
        "        # BERT encoding\n",
        "        encoder_layer, _ = self.bert(bert_token, bert_segment, output_all_encoded_layers=False)\n",
        "        batch_size, segment_len = bert_segment.size()\n",
        "        max_segment_len = bert_segment.argmax(dim=-1, keepdim=True)\n",
        "        batch_arrange = torch.arange(segment_len).unsqueeze(0).expand(batch_size, segment_len).to(bert_segment.device)\n",
        "        segment_mask = batch_arrange <= max_segment_len\n",
        "        sentence_mask = segment_mask & (1 - bert_segment).byte()\n",
        "        aspect_mask = bert_segment\n",
        "        sentence_lens = sentence_mask.long().sum(dim=1, keepdim=True)\n",
        "        # aspect average pooling\n",
        "        aspect_lens = aspect_mask.long().sum(dim=1, keepdim=True)\n",
        "        aspect = encoder_layer.masked_fill(aspect_mask.unsqueeze(-1) == 0, 0)\n",
        "        aspect = aspect.sum(dim=1, keepdim=False) / aspect_lens.float()\n",
        "        # sentence encode layer\n",
        "        max_len = sentence_lens.max().item()\n",
        "        sentence = encoder_layer[:, 0: max_len].contiguous()\n",
        "        sentence_mask = sentence_mask[:, 0: max_len].contiguous()\n",
        "        sentence = sentence.masked_fill(sentence_mask.unsqueeze(-1) == 0, 0)\n",
        "        # primary capsule layer\n",
        "        sentence = self.sentence_transform(sentence)\n",
        "        primary_capsule = squash(sentence, dim=-1)\n",
        "        aspect = self.aspect_transform(aspect)\n",
        "        aspect_capsule = squash(aspect, dim=-1)\n",
        "        # aspect aware normalization\n",
        "        norm_weight = self.norm_attention.get_attention_weights(aspect_capsule, primary_capsule, sentence_mask)\n",
        "        # capsule guided routing\n",
        "        category_capsule = self._capsule_guided_routing(primary_capsule, norm_weight)\n",
        "        category_capsule_norm = torch.sqrt(torch.sum(category_capsule * category_capsule, dim=-1, keepdim=False))\n",
        "        return category_capsule_norm\n",
        "\n",
        "    def _capsule_guided_routing(self, primary_capsule, norm_weight):\n",
        "        guide_capsule = squash(self.guide_capsule)\n",
        "        guide_matrix = primary_capsule.matmul(self.guide_weight).matmul(guide_capsule.transpose(0, 1))\n",
        "        guide_matrix = F.softmax(guide_matrix, dim=-1)\n",
        "        guide_matrix = guide_matrix * norm_weight.unsqueeze(-1) * self.scale  # (batch_size, time_step, num_categories)\n",
        "        category_capsule = guide_matrix.transpose(1, 2).matmul(primary_capsule)\n",
        "        category_capsule = F.dropout(category_capsule, p=self.dropout, training=self.training)\n",
        "        category_capsule = squash(category_capsule)\n",
        "        return category_capsule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "jm5pPZ4IdL3O"
      },
      "outputs": [],
      "source": [
        "class CapsuleLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, smooth=0.1, lamda=0.6):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.lamda = lamda\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        one_hot = torch.zeros_like(input).to(input.device)\n",
        "        one_hot = one_hot.scatter(1, target.unsqueeze(-1), 1)\n",
        "        a = torch.max(torch.zeros_like(input).to(input.device), 1 - self.smooth - input)\n",
        "        b = torch.max(torch.zeros_like(input).to(input.device), input - self.smooth)\n",
        "        loss = one_hot * a * a + self.lamda * (1 - one_hot) * b * b\n",
        "        loss = loss.sum(dim=1, keepdim=False)\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zUocDDn_J8"
      },
      "source": [
        "# **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "Qibh7tV9dL3B"
      },
      "outputs": [],
      "source": [
        "def parse_sentence_term(path, lowercase=False):\n",
        "    # parse each sentence into a tree by built-in xml function\n",
        "    tree = parse(path)\n",
        "    \n",
        "    # from here down parse each sentence to \n",
        "    # '[text], [term], [polarity], [from], [to]' with '_split_' inbetween,\n",
        "    # then append to data list. \n",
        "    sentences = tree.getroot()\n",
        "    data = []\n",
        "    split_char = '__split__'\n",
        "    for sentence in sentences:\n",
        "        text = sentence.find('text')\n",
        "        if text is None:\n",
        "            continue\n",
        "        text = text.text\n",
        "        if lowercase:\n",
        "            text = text.lower()\n",
        "        aspectTerms = sentence.find('aspectTerms')\n",
        "        if aspectTerms is None:\n",
        "            continue\n",
        "        for aspectTerm in aspectTerms:\n",
        "            term = aspectTerm.get('term')\n",
        "            if lowercase:\n",
        "                term = term.lower()\n",
        "            polarity = aspectTerm.get('polarity')\n",
        "            start = aspectTerm.get('from')\n",
        "            end = aspectTerm.get('to')\n",
        "            piece = text + split_char + term + split_char + polarity + split_char + start + split_char + end\n",
        "            data.append(piece)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "yXdUqmP3dL3D"
      },
      "outputs": [],
      "source": [
        "def category_filter(data, remove_list):\n",
        "    # remove conflicts, only allows polarity 'positive', 'neutral', 'negative'\n",
        "    remove_set = set(remove_list)\n",
        "    filtered_data = []\n",
        "    for text in data:\n",
        "        if not text.split('__split__')[2] in remove_set:\n",
        "            filtered_data.append(text)\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "DndCoFiRnduh"
      },
      "outputs": [],
      "source": [
        "def check(x):\n",
        "    return len(x) >= 1 and not x.isspace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "nxke1zzhne82"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
        "    return list(filter(check, tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "yNavxTnmngNP"
      },
      "outputs": [],
      "source": [
        "def build_vocab(data, max_size, min_freq):\n",
        "    if max_size == 'None':\n",
        "        max_size = None\n",
        "    vocab = Vocab()\n",
        "    for piece in data:\n",
        "        text = piece.split('__split__')[0]\n",
        "        text = tokenizer(text)\n",
        "        vocab.add_list(text)\n",
        "    return vocab.get_vocab(max_size=max_size, min_freq=min_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "JIdJFNQvdL3F"
      },
      "outputs": [],
      "source": [
        "def save_term_data(data, word2index, path):\n",
        "    dirname = os.path.dirname(path)\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    sentence = []\n",
        "    aspect = []\n",
        "    label = []\n",
        "    context = []\n",
        "    bert_token = []\n",
        "    bert_segment = []\n",
        "    td_left = []\n",
        "    td_right = []\n",
        "    f = lambda x: word2index[x] if x in word2index else word2index[UNK]\n",
        "    g = lambda x: list(map(f, tokenizer(x)))\n",
        "    d = {\n",
        "        'negative': 0,\n",
        "        'neutral': 1,\n",
        "        'positive': 2,\n",
        "        'conflict': 3\n",
        "    }\n",
        "    for piece in data:\n",
        "        text, term, polarity, start, end = piece.split('__split__')\n",
        "        start, end = int(start), int(end)\n",
        "        assert text[start: end] == term\n",
        "        # sentence appends tokenizer of text\n",
        "        sentence.append(g(text))\n",
        "        # aspect appends tokenizer of term\n",
        "        aspect.append(g(term))\n",
        "        # label appends index of polarity (based on d)\n",
        "        label.append(d[polarity])\n",
        "        # left extracts text to left of term\n",
        "        left_part = g(text[:start])\n",
        "        # right extracts text to right of term\n",
        "        right_part = g(text[end:])\n",
        "        # masking the term, show only text without term\n",
        "        context.append(left_part + [ASPECT_INDEX] + right_part)\n",
        "        bert_sentence = bert_tokenizer.tokenize(text)\n",
        "        bert_aspect = bert_tokenizer.tokenize(term)\n",
        "        # appends bert_text, bert_sentence, bert_aspect to token\n",
        "        bert_token.append(bert_tokenizer.convert_tokens_to_ids(['[CLS]'] + bert_sentence + ['[SEP]'] + bert_aspect + ['[SEP]']))\n",
        "        bert_segment.append([0] * (len(bert_sentence) + 2) + [1] * (len(bert_aspect) + 1))\n",
        "        # td left appends the text from 0 to end of term\n",
        "        td_left.append(g(text[:end]))\n",
        "        # td right appends the text from start of term to end of sentence\n",
        "        td_right.append(g(text[start:])[::-1])\n",
        "        assert len(bert_token[-1]) == len(bert_segment[-1])\n",
        "\n",
        "    max_length = lambda x: max([len(y) for y in x])\n",
        "    sentence_max_len = max_length(sentence)\n",
        "    aspect_max_len = max_length(aspect)\n",
        "    context_max_len = max_length(context)\n",
        "    bert_max_len = max_length(bert_token)\n",
        "    td_left_max_len = max_length(td_left)\n",
        "    td_right_max_len = max_length(td_right)\n",
        "    num = len(data)\n",
        "    for i in range(num):\n",
        "        # pads each list\n",
        "        sentence[i].extend([0] * (sentence_max_len - len(sentence[i])))\n",
        "        aspect[i].extend([0] * (aspect_max_len - len(aspect[i])))\n",
        "        context[i].extend([0] * (context_max_len - len(context[i])))\n",
        "        bert_token[i].extend([0] * (bert_max_len - len(bert_token[i])))\n",
        "        bert_segment[i].extend([0] * (bert_max_len - len(bert_segment[i])))\n",
        "        td_left[i].extend([0] * (td_left_max_len - len(td_left[i])))\n",
        "        td_right[i].extend([0] * (td_right_max_len - len(td_right[i])))\n",
        "    sentence = np.asarray(sentence, dtype=np.int32)\n",
        "    aspect = np.asarray(aspect, dtype=np.int32)\n",
        "    label = np.asarray(label, dtype=np.int32)\n",
        "    context = np.asarray(context, dtype=np.int32)\n",
        "    bert_token = np.asarray(bert_token, dtype=np.int32)\n",
        "    bert_segment = np.asarray(bert_segment, dtype=np.int32)\n",
        "    td_left = np.asarray(td_left, dtype=np.int32)\n",
        "    td_right = np.asarray(td_right, dtype=np.int32)\n",
        "    np.savez(path, sentence=sentence, aspect=aspect, label=label, context=context, bert_token=bert_token, bert_segment=bert_segment,\n",
        "             td_left=td_left, td_right=td_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "a9mXiH6SdL3I"
      },
      "outputs": [],
      "source": [
        "def load_sentiment_matrix(glove_path, sentiment_path):\n",
        "    # load hardcoded sentiments and add to vector analysis\n",
        "    sentiment_matrix = np.zeros((3, 300), dtype=np.float32)\n",
        "    sd = json.load(open(sentiment_path, 'r', encoding='utf-8'))\n",
        "    sd['positive'] = set(sd['positive'])\n",
        "    sd['negative'] = set(sd['negative'])\n",
        "    sd['neutral'] = set(sd['neutral'])\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            word = content[0]\n",
        "            vec = np.array(list(map(float, content[1:])))\n",
        "            if word in sd['positive']:\n",
        "                sentiment_matrix[0] += vec\n",
        "            elif word in sd['negative']:\n",
        "                sentiment_matrix[1] += vec\n",
        "            elif word in sd['neutral']:\n",
        "                sentiment_matrix[2] += vec\n",
        "    # normalization\n",
        "    sentiment_matrix -= sentiment_matrix.mean()\n",
        "    sentiment_matrix = sentiment_matrix / sentiment_matrix.std() * np.sqrt(2.0 / (300.0 + 3.0))\n",
        "    return sentiment_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "l_9sUTDrdL3J"
      },
      "outputs": [],
      "source": [
        "def analyze_term(data):\n",
        "    num = len(data)\n",
        "    sentence_lens = []\n",
        "    aspect_lens = []\n",
        "    log = {'total': num}\n",
        "    for piece in data:\n",
        "        text, term, polarity, _, _ = piece.split('__split__')\n",
        "        sentence_lens.append(len(tokenizer(text)))\n",
        "        aspect_lens.append(len(tokenizer(term)))\n",
        "        if not polarity in log:\n",
        "            log[polarity] = 0\n",
        "        log[polarity] += 1\n",
        "    log['sentence_max_len'] = max(sentence_lens)\n",
        "    log['sentence_avg_len'] = sum(sentence_lens) / len(sentence_lens)\n",
        "    log['aspect_max_len'] = max(aspect_lens)\n",
        "    log['aspect_avg_len'] = sum(aspect_lens) / len(aspect_lens)\n",
        "    return log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "BHOvLH3wdL3K"
      },
      "outputs": [],
      "source": [
        "def sentence_clip(sentence):\n",
        "    mask = (sentence != PAD_INDEX)\n",
        "    sentence_lens = mask.long().sum(dim=1, keepdim=False)\n",
        "    max_len = sentence_lens.max().item()\n",
        "    return sentence[:, :max_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "xA0qo61ydL3K"
      },
      "outputs": [],
      "source": [
        "def squash(x, dim=-1):\n",
        "    squared = torch.sum(x * x, dim=dim, keepdim=True)\n",
        "    scale = torch.sqrt(squared) / (1.0 + squared)\n",
        "    return scale * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "OpOafbYKdL3P"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    base_path = os.path.join(config['base_path'])\n",
        "    log_path = os.path.join(base_path, 'log/log.yml')\n",
        "    log = yaml.safe_load(open(log_path))\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model = BertCapsuleNetwork(\n",
        "        bert=bert,\n",
        "        bert_size=config2['bert_size'],\n",
        "        capsule_size=config2['capsule_size'],\n",
        "        dropout=config2['dropout'],\n",
        "        num_categories=log['num_categories']\n",
        "    )\n",
        "    model.load_sentiment(os.path.join(base_path, 'processed/sentiment_matrix.npy'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "v6MxubyGdL3P"
      },
      "outputs": [],
      "source": [
        "def make_term_data():\n",
        "    base_path = config['base_path']\n",
        "    train_path = os.path.join(base_path, 'processed/train.npz')\n",
        "    val_path = os.path.join(base_path, 'processed/val.npz')\n",
        "    train_data = ABSADataset(train_path, ['bert_token', 'bert_segment'])\n",
        "    val_data = ABSADataset(val_path, ['bert_token', 'bert_segment'])\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "My00r6pHROw2"
      },
      "outputs": [],
      "source": [
        "def make_term_test_data(config):\n",
        "    base_path = config['base_path']\n",
        "    test_path = os.path.join(base_path, 'processed/test.npz')\n",
        "    test_data = ABSADataset(test_path, ['bert_token', 'bert_segment'])\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "pMlnUPFBdL3Q"
      },
      "outputs": [],
      "source": [
        "def make_optimizer(model):\n",
        "    lr = config2['learning_rate']\n",
        "    weight_decay = config2['weight_decay']\n",
        "    opt = {\n",
        "        'sgd': optim.SGD,\n",
        "        'adadelta': optim.Adadelta,\n",
        "        'adam': optim.Adam,\n",
        "        'adamax': optim.Adamax,\n",
        "        'adagrad': optim.Adagrad,\n",
        "        'asgd': optim.ASGD,\n",
        "        'rmsprop': optim.RMSprop,\n",
        "        'adabound': adabound.AdaBound\n",
        "    }\n",
        "    if 'momentum' in config:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay, momentum=config2['momentum'])\n",
        "    else:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "IdlmWNmEomRD"
      },
      "outputs": [],
      "source": [
        "def eval(model, data_loader, criterion=None):\n",
        "    total_samples = 0\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "    list_of_labels = []\n",
        "    list_of_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label).item() if criterion is not None else 0\n",
        "            total_samples += input0.size(0)\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            total_loss += loss * input0.size(0)\n",
        "            list_of_labels.append(label)\n",
        "            list_of_predictions.append(pred)\n",
        "    accuracy = correct_samples / total_samples\n",
        "    avg_loss = total_loss / total_samples\n",
        "    if criterion is not None:\n",
        "        return accuracy, avg_loss\n",
        "    else:\n",
        "        return accuracy, list_of_labels, list_of_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "zAbKjs4wjARE"
      },
      "outputs": [],
      "source": [
        "def load_glove(path, vocab_size, word2index):\n",
        "    if not os.path.isfile(path):\n",
        "        raise IOError('Not a file', path)\n",
        "    glove = np.random.uniform(-0.01, 0.01, [vocab_size, 300])\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            if content[0] in word2index:\n",
        "                glove[word2index[content[0]]] = np.array(list(map(float, content[1:])))\n",
        "    glove[PAD_INDEX, :] = 0\n",
        "    return glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "fhYTiEFedL3U"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "    # parse data into list\n",
        "    train_data = parse_sentence_term(config['raw_train_path'], lowercase=config['lowercase'])\n",
        "    val_data = parse_sentence_term(config['raw_val_path'], lowercase=config['lowercase'])\n",
        "    test_data = parse_sentence_term(config['raw_test_path'], lowercase=config['lowercase'])\n",
        "    # filter conflicts\n",
        "    remove_list = ['conflict']\n",
        "    train_data = category_filter(train_data, remove_list)\n",
        "    val_data = category_filter(val_data, remove_list)\n",
        "    test_data = category_filter(test_data, remove_list)\n",
        "    # get the word2index and index2word of the parsed data\n",
        "    word2index, index2word = build_vocab(train_data, max_size=config['max_vocab_size'], min_freq=config['min_vocab_freq'])\n",
        "\n",
        "    # create path for the processed data\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'processed')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'processed'))\n",
        "    \n",
        "          \n",
        "    save_term_data(train_data, word2index, os.path.join(config[\"base_path\"], 'processed/train.npz'))\n",
        "    save_term_data(val_data, word2index, os.path.join(config[\"base_path\"], 'processed/val.npz'))\n",
        "    save_term_data(test_data, word2index, os.path.join(config[\"base_path\"], 'processed/test.npz'))\n",
        "\n",
        "    glove = load_glove(config['glove_path'], len(index2word), word2index)\n",
        "\n",
        "    sentiment_matrix = load_sentiment_matrix(config['glove_path'], config['sentiment_path'])\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/glove.npy'), glove)\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/sentiment_matrix.npy'), sentiment_matrix)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/word2index.pickle'), 'wb') as handle:\n",
        "        pickle.dump(word2index, handle)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/index2word.pickle'), 'wb') as handle:\n",
        "        pickle.dump(index2word, handle)\n",
        "    analyze = analyze_term\n",
        "    log = {\n",
        "        'vocab_size': len(index2word),\n",
        "        'oov_size': len(word2index) - len(index2word),\n",
        "        'train_data': analyze(train_data),\n",
        "        'val_data': analyze(val_data),\n",
        "        'test_data': analyze(test_data),\n",
        "        'num_categories': 3\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'log')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'log'))\n",
        "    with open(os.path.join(config[\"base_path\"], 'log/log.yml'), 'w') as handle:\n",
        "        yaml.safe_dump(log, handle, encoding='utf-8', allow_unicode=True, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "BQS3yFtDdL3Q"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    train_loader, val_loader = make_term_data()\n",
        "    global model\n",
        "    model = model.cuda()\n",
        "    base_path = config['base_path']\n",
        "    model_path = os.path.join(base_path, 'checkpoints/%s.pth' % \"bert_capsnet\")\n",
        "    if not os.path.exists(os.path.dirname(model_path)):\n",
        "        os.makedirs(os.path.dirname(model_path))\n",
        "    with open(os.path.join(base_path, 'processed/index2word.pickle'), 'rb') as handle:\n",
        "        index2word = pickle.load(handle)\n",
        "    criterion = CapsuleLoss()\n",
        "    optimizer = make_optimizer(model)\n",
        "    max_val_accuracy = 0\n",
        "    min_val_loss = 100\n",
        "    global_step = 0\n",
        "    \n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "\n",
        "\n",
        "    for epoch in range(config2['num_epoches']):\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        correct_samples = 0\n",
        "        start = time.time()\n",
        "        for i, data in enumerate(train_loader):\n",
        "            global_step += 1\n",
        "            model.train()\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label)\n",
        "            batch_size = input0.size(0)\n",
        "            total_loss += batch_size * loss.item()\n",
        "            total_samples += batch_size\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "            if i % 10 == 0 and i > 0:\n",
        "                train_loss = total_loss / total_samples\n",
        "                train_accuracy = correct_samples / total_samples\n",
        "                total_loss = 0\n",
        "                total_samples = 0\n",
        "                correct_samples = 0\n",
        "                val_accuracy, val_loss = eval(model, val_loader, criterion)\n",
        "                \n",
        "                print('[epoch %2d] [step %3d] train_loss: %.4f train_acc: %.4f val_loss: %.4f val_acc: %.4f'\n",
        "                      % (epoch, i, train_loss, train_accuracy, val_loss, val_accuracy))\n",
        "                if val_accuracy > max_val_accuracy:\n",
        "                    max_val_accuracy = val_accuracy\n",
        "                    # torch.save(aspect_term_model.state_dict(), model_path)\n",
        "                if val_loss < min_val_loss:\n",
        "                    min_val_loss = val_loss\n",
        "                    if epoch > 0:\n",
        "                        torch.save(model.state_dict(), model_path)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_accuracy)\n",
        "        end = time.time()\n",
        "        print('time: %.4fs' % (end - start))\n",
        "    print('max_val_accuracy:', max_val_accuracy)\n",
        "    return train_losses, train_accs, val_losses, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "5qqjfQ_JQedA"
      },
      "outputs": [],
      "source": [
        "def make_bert_capsule_network(config):\n",
        "    base_path = os.path.join(config['base_path'])\n",
        "    log_path = os.path.join(base_path, 'log/log.yml')\n",
        "    log = yaml.safe_load(open(log_path))\n",
        "    config = config['aspect_term_model'][config['aspect_term_model']['type']]\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model = BertCapsuleNetwork(\n",
        "        bert=bert,\n",
        "        bert_size=config['bert_size'],\n",
        "        capsule_size=config['capsule_size'],\n",
        "        dropout=config['dropout'],\n",
        "        num_categories=log['num_categories']\n",
        "    )\n",
        "    model.load_sentiment(os.path.join(base_path, 'processed/sentiment_matrix.npy'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "A4wKGhJarlcg"
      },
      "outputs": [],
      "source": [
        "def convert_tensor_to_list(tensors):\n",
        "    ls = []\n",
        "    for row in tensors:\n",
        "        for ele in row:\n",
        "            ls.append(ele.item())\n",
        "\n",
        "    return ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "TjAknl6zQLUi"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    model = make_model()\n",
        "    model = model.cuda()\n",
        "    model_path = os.path.join(config['base_path'], 'checkpoints/%s.pth' % config['mode'])\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    epochs = config['num_epoches']\n",
        "    \n",
        "    test_loader = make_term_test_data(config)\n",
        "    test_accuracy, test_labels, final_prediction = eval(model, test_loader)\n",
        "    print('test:\\taccuracy: %.4f' % (test_accuracy))\n",
        "    return test_accuracy, test_labels, final_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4rZNufDpQNi"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as9UA-0NtyNS"
      },
      "source": [
        "### **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "conAL_dUdL3R"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"base_path\": \"drive/MyDrive/CS4248/MAMS-ATSA\",\n",
        "    \"mode\": \"bert_capsnet\",\n",
        "    \"glove_path\": \"drive/MyDrive/CS4248/glove.42B.300d.txt\",\n",
        "    \"sentiment_path\": \"drive/MyDrive/CS4248/sentiment_dict.json\",\n",
        "    \"max_vocab_size\": None,\n",
        "    \"min_vocab_freq\": 0,\n",
        "    \"lowercase\": True,\n",
        "    'bert_size': 768,\n",
        "    'capsule_size': 300,\n",
        "    'dropout': 0.1,\n",
        "    'optimizer': 'adam',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.00002,\n",
        "    'weight_decay': 0,\n",
        "    'num_epoches': 5,\n",
        "    'gpu': 0\n",
        "    }\n",
        "\n",
        "config[\"raw_train_path\"] = os.path.join(config[\"base_path\"], 'raw/train.xml')\n",
        "config[\"raw_val_path\"] = os.path.join(config[\"base_path\"], 'raw/val.xml')\n",
        "config[\"raw_test_path\"] = os.path.join(config['base_path'], 'raw/test.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "g0XX1iK3owFD"
      },
      "outputs": [],
      "source": [
        "config2 = {\n",
        "    'bert_size': 768,\n",
        "    'capsule_size': 300,\n",
        "    'dropout': 0.1,\n",
        "    'optimizer': 'adam',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.00002,\n",
        "    'weight_decay': 0,\n",
        "    'num_epoches': 5,\n",
        "    'gpu': 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOXozd3t573"
      },
      "source": [
        "### **Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "tjQxMzYWpzrt"
      },
      "outputs": [],
      "source": [
        "preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "ay3c-MAfdL3W"
      },
      "outputs": [],
      "source": [
        "model = make_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK0iM2ZZdL3W",
        "outputId": "9bb53663-ecaf-4de7-d0d8-6389cd49fc80",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch  0] [step  10] train_loss: 0.3433 train_acc: 0.4375 val_loss: 0.3381 val_acc: 0.4535\n",
            "[epoch  0] [step  20] train_loss: 0.3366 train_acc: 0.4656 val_loss: 0.3354 val_acc: 0.4535\n",
            "[epoch  0] [step  30] train_loss: 0.3340 train_acc: 0.4656 val_loss: 0.3341 val_acc: 0.4535\n",
            "[epoch  0] [step  40] train_loss: 0.3387 train_acc: 0.4375 val_loss: 0.3328 val_acc: 0.4535\n",
            "[epoch  0] [step  50] train_loss: 0.3320 train_acc: 0.4594 val_loss: 0.3320 val_acc: 0.4535\n",
            "[epoch  0] [step  60] train_loss: 0.3326 train_acc: 0.4656 val_loss: 0.3309 val_acc: 0.4535\n",
            "[epoch  0] [step  70] train_loss: 0.3321 train_acc: 0.4594 val_loss: 0.3280 val_acc: 0.4535\n",
            "[epoch  0] [step  80] train_loss: 0.3276 train_acc: 0.4562 val_loss: 0.3225 val_acc: 0.4550\n",
            "[epoch  0] [step  90] train_loss: 0.3243 train_acc: 0.4437 val_loss: 0.3200 val_acc: 0.4715\n",
            "[epoch  0] [step 100] train_loss: 0.3127 train_acc: 0.5062 val_loss: 0.3104 val_acc: 0.5015\n",
            "[epoch  0] [step 110] train_loss: 0.3073 train_acc: 0.5250 val_loss: 0.3027 val_acc: 0.5728\n",
            "[epoch  0] [step 120] train_loss: 0.2986 train_acc: 0.5469 val_loss: 0.2935 val_acc: 0.5863\n",
            "[epoch  0] [step 130] train_loss: 0.2877 train_acc: 0.6031 val_loss: 0.2910 val_acc: 0.5811\n",
            "[epoch  0] [step 140] train_loss: 0.2952 train_acc: 0.5625 val_loss: 0.2800 val_acc: 0.6179\n",
            "[epoch  0] [step 150] train_loss: 0.2864 train_acc: 0.6000 val_loss: 0.2746 val_acc: 0.6164\n",
            "[epoch  0] [step 160] train_loss: 0.2814 train_acc: 0.5906 val_loss: 0.2773 val_acc: 0.6201\n",
            "[epoch  0] [step 170] train_loss: 0.2948 train_acc: 0.5594 val_loss: 0.2668 val_acc: 0.6396\n",
            "[epoch  0] [step 180] train_loss: 0.2573 train_acc: 0.6750 val_loss: 0.2640 val_acc: 0.6209\n",
            "[epoch  0] [step 190] train_loss: 0.2584 train_acc: 0.6312 val_loss: 0.2664 val_acc: 0.6269\n",
            "[epoch  0] [step 200] train_loss: 0.2773 train_acc: 0.6125 val_loss: 0.2628 val_acc: 0.6494\n",
            "[epoch  0] [step 210] train_loss: 0.2577 train_acc: 0.6844 val_loss: 0.2547 val_acc: 0.6562\n",
            "[epoch  0] [step 220] train_loss: 0.2536 train_acc: 0.6594 val_loss: 0.2487 val_acc: 0.6667\n",
            "[epoch  0] [step 230] train_loss: 0.2454 train_acc: 0.6094 val_loss: 0.2524 val_acc: 0.6494\n",
            "[epoch  0] [step 240] train_loss: 0.2637 train_acc: 0.6125 val_loss: 0.2381 val_acc: 0.7065\n",
            "[epoch  0] [step 250] train_loss: 0.2517 train_acc: 0.6750 val_loss: 0.2250 val_acc: 0.7237\n",
            "[epoch  0] [step 260] train_loss: 0.2472 train_acc: 0.6781 val_loss: 0.2161 val_acc: 0.7222\n",
            "[epoch  0] [step 270] train_loss: 0.2208 train_acc: 0.7344 val_loss: 0.2124 val_acc: 0.7628\n",
            "[epoch  0] [step 280] train_loss: 0.2169 train_acc: 0.7312 val_loss: 0.2073 val_acc: 0.7500\n",
            "[epoch  0] [step 290] train_loss: 0.2037 train_acc: 0.7250 val_loss: 0.2001 val_acc: 0.7568\n",
            "[epoch  0] [step 300] train_loss: 0.2018 train_acc: 0.7656 val_loss: 0.1940 val_acc: 0.7673\n",
            "[epoch  0] [step 310] train_loss: 0.1993 train_acc: 0.7625 val_loss: 0.1893 val_acc: 0.7793\n",
            "[epoch  0] [step 320] train_loss: 0.1848 train_acc: 0.7937 val_loss: 0.1910 val_acc: 0.7740\n",
            "[epoch  0] [step 330] train_loss: 0.1824 train_acc: 0.7969 val_loss: 0.1878 val_acc: 0.7620\n",
            "[epoch  0] [step 340] train_loss: 0.1798 train_acc: 0.7969 val_loss: 0.1939 val_acc: 0.7575\n",
            "time: 519.0826s\n",
            "[epoch  1] [step  10] train_loss: 0.1714 train_acc: 0.7926 val_loss: 0.1812 val_acc: 0.7800\n",
            "[epoch  1] [step  20] train_loss: 0.1695 train_acc: 0.8031 val_loss: 0.1922 val_acc: 0.7508\n",
            "[epoch  1] [step  30] train_loss: 0.1828 train_acc: 0.7812 val_loss: 0.1762 val_acc: 0.7830\n",
            "[epoch  1] [step  40] train_loss: 0.1564 train_acc: 0.8219 val_loss: 0.1706 val_acc: 0.7890\n",
            "[epoch  1] [step  50] train_loss: 0.1619 train_acc: 0.7969 val_loss: 0.1646 val_acc: 0.7920\n",
            "[epoch  1] [step  60] train_loss: 0.1476 train_acc: 0.8281 val_loss: 0.1715 val_acc: 0.7823\n",
            "[epoch  1] [step  70] train_loss: 0.1751 train_acc: 0.7844 val_loss: 0.1590 val_acc: 0.8048\n",
            "[epoch  1] [step  80] train_loss: 0.1591 train_acc: 0.8094 val_loss: 0.1555 val_acc: 0.8063\n",
            "[epoch  1] [step  90] train_loss: 0.1395 train_acc: 0.8063 val_loss: 0.1554 val_acc: 0.7980\n",
            "[epoch  1] [step 100] train_loss: 0.1559 train_acc: 0.7969 val_loss: 0.1589 val_acc: 0.7905\n",
            "[epoch  1] [step 110] train_loss: 0.1543 train_acc: 0.8000 val_loss: 0.1574 val_acc: 0.7928\n",
            "[epoch  1] [step 120] train_loss: 0.1532 train_acc: 0.8219 val_loss: 0.1551 val_acc: 0.7965\n",
            "[epoch  1] [step 130] train_loss: 0.1564 train_acc: 0.7875 val_loss: 0.1581 val_acc: 0.7980\n",
            "[epoch  1] [step 140] train_loss: 0.1672 train_acc: 0.7875 val_loss: 0.1700 val_acc: 0.7845\n",
            "[epoch  1] [step 150] train_loss: 0.1370 train_acc: 0.8344 val_loss: 0.1536 val_acc: 0.8056\n",
            "[epoch  1] [step 160] train_loss: 0.1382 train_acc: 0.8344 val_loss: 0.1538 val_acc: 0.8063\n",
            "[epoch  1] [step 170] train_loss: 0.1357 train_acc: 0.8281 val_loss: 0.1546 val_acc: 0.8041\n",
            "[epoch  1] [step 180] train_loss: 0.1513 train_acc: 0.8031 val_loss: 0.1605 val_acc: 0.7860\n",
            "[epoch  1] [step 190] train_loss: 0.1230 train_acc: 0.8562 val_loss: 0.1555 val_acc: 0.8026\n",
            "[epoch  1] [step 200] train_loss: 0.1534 train_acc: 0.7875 val_loss: 0.1583 val_acc: 0.7988\n",
            "[epoch  1] [step 210] train_loss: 0.1651 train_acc: 0.7844 val_loss: 0.1585 val_acc: 0.7965\n",
            "[epoch  1] [step 220] train_loss: 0.1712 train_acc: 0.7844 val_loss: 0.1587 val_acc: 0.8003\n",
            "[epoch  1] [step 230] train_loss: 0.1402 train_acc: 0.8219 val_loss: 0.1539 val_acc: 0.8063\n",
            "[epoch  1] [step 240] train_loss: 0.1467 train_acc: 0.8219 val_loss: 0.1520 val_acc: 0.7995\n",
            "[epoch  1] [step 250] train_loss: 0.1314 train_acc: 0.8375 val_loss: 0.1504 val_acc: 0.8011\n",
            "[epoch  1] [step 260] train_loss: 0.1407 train_acc: 0.8125 val_loss: 0.1547 val_acc: 0.7890\n",
            "[epoch  1] [step 270] train_loss: 0.1403 train_acc: 0.8250 val_loss: 0.1501 val_acc: 0.8033\n",
            "[epoch  1] [step 280] train_loss: 0.1277 train_acc: 0.8375 val_loss: 0.1555 val_acc: 0.7980\n",
            "[epoch  1] [step 290] train_loss: 0.1542 train_acc: 0.7844 val_loss: 0.1496 val_acc: 0.8063\n",
            "[epoch  1] [step 300] train_loss: 0.1257 train_acc: 0.8344 val_loss: 0.1491 val_acc: 0.8071\n",
            "[epoch  1] [step 310] train_loss: 0.1177 train_acc: 0.8500 val_loss: 0.1528 val_acc: 0.8041\n",
            "[epoch  1] [step 320] train_loss: 0.1445 train_acc: 0.8250 val_loss: 0.1541 val_acc: 0.7980\n",
            "[epoch  1] [step 330] train_loss: 0.1347 train_acc: 0.8313 val_loss: 0.1546 val_acc: 0.7980\n",
            "[epoch  1] [step 340] train_loss: 0.1434 train_acc: 0.8000 val_loss: 0.1498 val_acc: 0.8116\n",
            "time: 542.1049s\n",
            "[epoch  2] [step  10] train_loss: 0.0764 train_acc: 0.9148 val_loss: 0.1523 val_acc: 0.8078\n",
            "[epoch  2] [step  20] train_loss: 0.0971 train_acc: 0.8906 val_loss: 0.1534 val_acc: 0.8191\n",
            "[epoch  2] [step  30] train_loss: 0.1059 train_acc: 0.8781 val_loss: 0.1576 val_acc: 0.7958\n",
            "[epoch  2] [step  40] train_loss: 0.0859 train_acc: 0.9031 val_loss: 0.1501 val_acc: 0.8161\n",
            "[epoch  2] [step  50] train_loss: 0.1015 train_acc: 0.8719 val_loss: 0.1528 val_acc: 0.8078\n",
            "[epoch  2] [step  60] train_loss: 0.0967 train_acc: 0.8719 val_loss: 0.1617 val_acc: 0.7950\n",
            "[epoch  2] [step  70] train_loss: 0.1180 train_acc: 0.8625 val_loss: 0.1549 val_acc: 0.8011\n",
            "[epoch  2] [step  80] train_loss: 0.0921 train_acc: 0.8938 val_loss: 0.1512 val_acc: 0.8041\n",
            "[epoch  2] [step  90] train_loss: 0.1057 train_acc: 0.8625 val_loss: 0.1643 val_acc: 0.7853\n",
            "[epoch  2] [step 100] train_loss: 0.0956 train_acc: 0.8812 val_loss: 0.1562 val_acc: 0.8033\n",
            "[epoch  2] [step 110] train_loss: 0.0930 train_acc: 0.8875 val_loss: 0.1532 val_acc: 0.8116\n",
            "[epoch  2] [step 120] train_loss: 0.0810 train_acc: 0.9094 val_loss: 0.1540 val_acc: 0.8116\n",
            "[epoch  2] [step 130] train_loss: 0.0827 train_acc: 0.8969 val_loss: 0.1570 val_acc: 0.8056\n",
            "[epoch  2] [step 140] train_loss: 0.0978 train_acc: 0.8812 val_loss: 0.1512 val_acc: 0.8146\n",
            "[epoch  2] [step 150] train_loss: 0.0875 train_acc: 0.9062 val_loss: 0.1533 val_acc: 0.8138\n",
            "[epoch  2] [step 160] train_loss: 0.1190 train_acc: 0.8594 val_loss: 0.1581 val_acc: 0.7973\n",
            "[epoch  2] [step 170] train_loss: 0.0883 train_acc: 0.8969 val_loss: 0.1468 val_acc: 0.8198\n",
            "[epoch  2] [step 180] train_loss: 0.1033 train_acc: 0.8656 val_loss: 0.1453 val_acc: 0.8176\n",
            "[epoch  2] [step 190] train_loss: 0.0906 train_acc: 0.8781 val_loss: 0.1510 val_acc: 0.8116\n",
            "[epoch  2] [step 200] train_loss: 0.0988 train_acc: 0.8750 val_loss: 0.1516 val_acc: 0.8048\n",
            "[epoch  2] [step 210] train_loss: 0.1169 train_acc: 0.8344 val_loss: 0.1468 val_acc: 0.8101\n",
            "[epoch  2] [step 220] train_loss: 0.0987 train_acc: 0.8781 val_loss: 0.1439 val_acc: 0.8183\n",
            "[epoch  2] [step 230] train_loss: 0.0986 train_acc: 0.8812 val_loss: 0.1475 val_acc: 0.8131\n",
            "[epoch  2] [step 240] train_loss: 0.1159 train_acc: 0.8594 val_loss: 0.1469 val_acc: 0.8108\n",
            "[epoch  2] [step 250] train_loss: 0.0944 train_acc: 0.8781 val_loss: 0.1440 val_acc: 0.8228\n",
            "[epoch  2] [step 260] train_loss: 0.0910 train_acc: 0.8875 val_loss: 0.1463 val_acc: 0.8116\n",
            "[epoch  2] [step 270] train_loss: 0.1086 train_acc: 0.8625 val_loss: 0.1559 val_acc: 0.7973\n",
            "[epoch  2] [step 280] train_loss: 0.0990 train_acc: 0.8656 val_loss: 0.1450 val_acc: 0.8176\n",
            "[epoch  2] [step 290] train_loss: 0.0900 train_acc: 0.8875 val_loss: 0.1454 val_acc: 0.8146\n",
            "[epoch  2] [step 300] train_loss: 0.0980 train_acc: 0.8844 val_loss: 0.1414 val_acc: 0.8206\n",
            "[epoch  2] [step 310] train_loss: 0.0956 train_acc: 0.8812 val_loss: 0.1408 val_acc: 0.8213\n",
            "[epoch  2] [step 320] train_loss: 0.0879 train_acc: 0.8938 val_loss: 0.1447 val_acc: 0.8288\n",
            "[epoch  2] [step 330] train_loss: 0.0593 train_acc: 0.9313 val_loss: 0.1450 val_acc: 0.8258\n",
            "[epoch  2] [step 340] train_loss: 0.0938 train_acc: 0.8688 val_loss: 0.1439 val_acc: 0.8213\n",
            "[epoch  3] [step  10] train_loss: 0.0812 train_acc: 0.9034 val_loss: 0.1482 val_acc: 0.8221\n",
            "[epoch  3] [step  20] train_loss: 0.0712 train_acc: 0.9125 val_loss: 0.1573 val_acc: 0.8063\n",
            "[epoch  3] [step  30] train_loss: 0.0730 train_acc: 0.9125 val_loss: 0.1458 val_acc: 0.8243\n",
            "[epoch  3] [step  40] train_loss: 0.0746 train_acc: 0.9156 val_loss: 0.1500 val_acc: 0.8198\n",
            "[epoch  3] [step  50] train_loss: 0.0514 train_acc: 0.9469 val_loss: 0.1524 val_acc: 0.8153\n",
            "[epoch  3] [step  60] train_loss: 0.0619 train_acc: 0.9281 val_loss: 0.1474 val_acc: 0.8288\n",
            "[epoch  3] [step  70] train_loss: 0.0629 train_acc: 0.9313 val_loss: 0.1530 val_acc: 0.8191\n",
            "[epoch  3] [step  80] train_loss: 0.0634 train_acc: 0.9187 val_loss: 0.1488 val_acc: 0.8266\n",
            "[epoch  3] [step  90] train_loss: 0.0588 train_acc: 0.9281 val_loss: 0.1507 val_acc: 0.8258\n",
            "[epoch  3] [step 100] train_loss: 0.0597 train_acc: 0.9250 val_loss: 0.1580 val_acc: 0.8101\n",
            "[epoch  3] [step 110] train_loss: 0.0673 train_acc: 0.9187 val_loss: 0.1573 val_acc: 0.8116\n",
            "[epoch  3] [step 120] train_loss: 0.0564 train_acc: 0.9406 val_loss: 0.1507 val_acc: 0.8161\n",
            "[epoch  3] [step 130] train_loss: 0.0768 train_acc: 0.9062 val_loss: 0.1492 val_acc: 0.8183\n",
            "[epoch  3] [step 140] train_loss: 0.0567 train_acc: 0.9313 val_loss: 0.1500 val_acc: 0.8206\n",
            "[epoch  3] [step 150] train_loss: 0.0845 train_acc: 0.8938 val_loss: 0.1567 val_acc: 0.8101\n",
            "[epoch  3] [step 160] train_loss: 0.0705 train_acc: 0.9250 val_loss: 0.1469 val_acc: 0.8198\n",
            "[epoch  3] [step 170] train_loss: 0.0578 train_acc: 0.9281 val_loss: 0.1461 val_acc: 0.8243\n",
            "[epoch  3] [step 180] train_loss: 0.0812 train_acc: 0.9000 val_loss: 0.1463 val_acc: 0.8228\n",
            "[epoch  3] [step 190] train_loss: 0.0721 train_acc: 0.9156 val_loss: 0.1477 val_acc: 0.8191\n",
            "[epoch  3] [step 200] train_loss: 0.0757 train_acc: 0.9062 val_loss: 0.1491 val_acc: 0.8176\n",
            "[epoch  3] [step 210] train_loss: 0.0741 train_acc: 0.9125 val_loss: 0.1521 val_acc: 0.8123\n",
            "[epoch  3] [step 220] train_loss: 0.0633 train_acc: 0.9250 val_loss: 0.1552 val_acc: 0.8093\n",
            "[epoch  3] [step 230] train_loss: 0.0615 train_acc: 0.9250 val_loss: 0.1532 val_acc: 0.8183\n",
            "[epoch  3] [step 240] train_loss: 0.0552 train_acc: 0.9375 val_loss: 0.1554 val_acc: 0.8146\n",
            "[epoch  3] [step 250] train_loss: 0.0623 train_acc: 0.9250 val_loss: 0.1529 val_acc: 0.8221\n",
            "[epoch  3] [step 260] train_loss: 0.0585 train_acc: 0.9344 val_loss: 0.1555 val_acc: 0.8131\n",
            "[epoch  3] [step 270] train_loss: 0.0731 train_acc: 0.9094 val_loss: 0.1505 val_acc: 0.8236\n",
            "[epoch  3] [step 280] train_loss: 0.0743 train_acc: 0.9062 val_loss: 0.1563 val_acc: 0.8116\n",
            "[epoch  3] [step 290] train_loss: 0.0819 train_acc: 0.8938 val_loss: 0.1546 val_acc: 0.8198\n",
            "[epoch  3] [step 300] train_loss: 0.0589 train_acc: 0.9250 val_loss: 0.1582 val_acc: 0.8078\n",
            "[epoch  3] [step 310] train_loss: 0.0666 train_acc: 0.9219 val_loss: 0.1505 val_acc: 0.8213\n",
            "[epoch  3] [step 320] train_loss: 0.0743 train_acc: 0.9156 val_loss: 0.1526 val_acc: 0.8176\n",
            "[epoch  3] [step 330] train_loss: 0.0649 train_acc: 0.9281 val_loss: 0.1581 val_acc: 0.8131\n",
            "[epoch  3] [step 340] train_loss: 0.0885 train_acc: 0.8875 val_loss: 0.1489 val_acc: 0.8206\n",
            "time: 520.3857s\n",
            "[epoch  4] [step  10] train_loss: 0.0476 train_acc: 0.9517 val_loss: 0.1495 val_acc: 0.8198\n",
            "[epoch  4] [step  20] train_loss: 0.0363 train_acc: 0.9563 val_loss: 0.1487 val_acc: 0.8258\n",
            "[epoch  4] [step  30] train_loss: 0.0372 train_acc: 0.9625 val_loss: 0.1693 val_acc: 0.8056\n",
            "[epoch  4] [step  40] train_loss: 0.0603 train_acc: 0.9375 val_loss: 0.1495 val_acc: 0.8213\n",
            "[epoch  4] [step  50] train_loss: 0.0480 train_acc: 0.9469 val_loss: 0.1467 val_acc: 0.8303\n",
            "[epoch  4] [step  60] train_loss: 0.0417 train_acc: 0.9531 val_loss: 0.1577 val_acc: 0.8191\n",
            "[epoch  4] [step  70] train_loss: 0.0329 train_acc: 0.9625 val_loss: 0.1471 val_acc: 0.8303\n",
            "[epoch  4] [step  80] train_loss: 0.0690 train_acc: 0.9187 val_loss: 0.1516 val_acc: 0.8266\n",
            "[epoch  4] [step  90] train_loss: 0.0649 train_acc: 0.9219 val_loss: 0.1464 val_acc: 0.8311\n",
            "[epoch  4] [step 100] train_loss: 0.0424 train_acc: 0.9500 val_loss: 0.1473 val_acc: 0.8258\n",
            "[epoch  4] [step 110] train_loss: 0.0592 train_acc: 0.9344 val_loss: 0.1524 val_acc: 0.8176\n",
            "[epoch  4] [step 120] train_loss: 0.0615 train_acc: 0.9281 val_loss: 0.1496 val_acc: 0.8198\n",
            "[epoch  4] [step 130] train_loss: 0.0675 train_acc: 0.9219 val_loss: 0.1466 val_acc: 0.8198\n",
            "[epoch  4] [step 140] train_loss: 0.0639 train_acc: 0.9062 val_loss: 0.1407 val_acc: 0.8236\n",
            "[epoch  4] [step 150] train_loss: 0.0403 train_acc: 0.9594 val_loss: 0.1567 val_acc: 0.8183\n",
            "[epoch  4] [step 160] train_loss: 0.0440 train_acc: 0.9406 val_loss: 0.1518 val_acc: 0.8206\n",
            "[epoch  4] [step 170] train_loss: 0.0465 train_acc: 0.9406 val_loss: 0.1470 val_acc: 0.8273\n",
            "[epoch  4] [step 180] train_loss: 0.0497 train_acc: 0.9437 val_loss: 0.1471 val_acc: 0.8236\n",
            "[epoch  4] [step 190] train_loss: 0.0416 train_acc: 0.9500 val_loss: 0.1577 val_acc: 0.8131\n",
            "[epoch  4] [step 200] train_loss: 0.0414 train_acc: 0.9469 val_loss: 0.1457 val_acc: 0.8341\n",
            "[epoch  4] [step 210] train_loss: 0.0410 train_acc: 0.9563 val_loss: 0.1562 val_acc: 0.8183\n",
            "[epoch  4] [step 220] train_loss: 0.0604 train_acc: 0.9250 val_loss: 0.1487 val_acc: 0.8236\n",
            "[epoch  4] [step 230] train_loss: 0.0459 train_acc: 0.9437 val_loss: 0.1478 val_acc: 0.8198\n",
            "[epoch  4] [step 240] train_loss: 0.0365 train_acc: 0.9563 val_loss: 0.1495 val_acc: 0.8311\n",
            "[epoch  4] [step 250] train_loss: 0.0459 train_acc: 0.9437 val_loss: 0.1463 val_acc: 0.8281\n",
            "[epoch  4] [step 260] train_loss: 0.0510 train_acc: 0.9406 val_loss: 0.1469 val_acc: 0.8266\n",
            "[epoch  4] [step 270] train_loss: 0.0463 train_acc: 0.9469 val_loss: 0.1666 val_acc: 0.8003\n",
            "[epoch  4] [step 280] train_loss: 0.0574 train_acc: 0.9344 val_loss: 0.1481 val_acc: 0.8273\n",
            "[epoch  4] [step 290] train_loss: 0.0437 train_acc: 0.9500 val_loss: 0.1526 val_acc: 0.8228\n",
            "[epoch  4] [step 300] train_loss: 0.0279 train_acc: 0.9688 val_loss: 0.1562 val_acc: 0.8176\n",
            "[epoch  4] [step 310] train_loss: 0.0541 train_acc: 0.9437 val_loss: 0.1560 val_acc: 0.8221\n",
            "[epoch  4] [step 320] train_loss: 0.0374 train_acc: 0.9531 val_loss: 0.1584 val_acc: 0.8168\n",
            "[epoch  4] [step 330] train_loss: 0.0505 train_acc: 0.9375 val_loss: 0.1516 val_acc: 0.8243\n",
            "[epoch  4] [step 340] train_loss: 0.0786 train_acc: 0.9000 val_loss: 0.1536 val_acc: 0.8236\n",
            "time: 522.1711s\n",
            "max_val_accuracy: 0.8340840840840841\n"
          ]
        }
      ],
      "source": [
        "losses, accs, val_losses, val_accs = train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZH08jYT2Uan",
        "outputId": "7798de42-490b-4171-8b46-2e178b1f3307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test:\taccuracy: 0.8278\n"
          ]
        }
      ],
      "source": [
        "test_accuracy, test_labels, final_prediction = test()\n",
        "test_labels = convert_tensor_to_list(test_labels)\n",
        "final_prediction = convert_tensor_to_list(final_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7mLJPkAgRY4",
        "outputId": "18aee14a-d5fa-4925-a26d-e703efb38d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8239182829309083\n",
            "0.8278443113772455\n",
            "0.8280656391867971\n",
            "\n",
            "0.8207768568178123\n",
            "0.8278443113772455\n",
            "0.8289138787271874\n",
            "\n",
            "0.8277598901034704\n",
            "0.8278443113772455\n",
            "0.8278443113772455\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f1_score(test_labels, final_prediction, average = \"macro\"))\n",
        "print(f1_score(test_labels, final_prediction, average = \"micro\"))\n",
        "print(f1_score(test_labels, final_prediction, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(precision_score(test_labels, final_prediction, average = \"macro\"))\n",
        "print(precision_score(test_labels, final_prediction, average = \"micro\"))\n",
        "print(precision_score(test_labels, final_prediction, average = \"weighted\"))\n",
        "print()\n",
        "\n",
        "print(recall_score(test_labels, final_prediction, average = \"macro\"))\n",
        "print(recall_score(test_labels, final_prediction, average = \"micro\"))\n",
        "print(recall_score(test_labels, final_prediction, average = \"weighted\"))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "eWHP28YywdrO",
        "outputId": "2f92902d-e66c-48cc-a5cf-0fc29efb34f0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = len(losses)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\n",
        "  plt.subplot(1, 2, i + 1)\n",
        "  plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\n",
        "  plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\n",
        "  plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('bert_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "U1F01aAK2uAU",
        "outputId": "a1fee379-c0cf-49b8-e3e7-8f27214ef2c8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "result = confusion_matrix(test_labels, final_prediction)\n",
        "cf_matrix = pd.DataFrame(result, \n",
        "                         columns = [\"Pred Negative\", \"Pred Neutral\", \"Pred Positive\"],\n",
        "                         index = [\"Actual Negative\", \"Actual Neutral\", \"Actual Positive\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cf_matrix, annot = True, cmap = 'Blues', fmt = '.3g')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('CS4248-project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "acc163ef47be86fb239cdb7a5b440891b3a074f9418fa7049e8ce9b17a74f46c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
