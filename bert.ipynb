{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVIi8VqQmDiX"
      },
      "source": [
        "## **SETUP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fW-S3vnmBR2"
      },
      "source": [
        "### **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thkmr3cIgUUf",
        "outputId": "7a862b48-3565-4562-b220-0e0f2c14fa00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-agNV-qKoU",
        "outputId": "a1cffbd0-32ee-499e-c11d-5379c3716d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adabound\n",
            "  Downloading adabound-0.0.5-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from adabound) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->adabound) (4.1.1)\n",
            "Installing collected packages: adabound\n",
            "Successfully installed adabound-0.0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.89-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.89\n",
            "  Downloading botocore-1.27.89-py3-none-any.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 64.2 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.89->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.89->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.89 botocore-1.27.89 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install adabound\n",
        "!pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOY16t1YdL29"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import yaml\n",
        "import random\n",
        "import spacy\n",
        "import re\n",
        "import json\n",
        "import operator\n",
        "import time\n",
        "import adabound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMn5SgbMnHLD"
      },
      "outputs": [],
      "source": [
        "from xml.etree.ElementTree import parse\n",
        "from pytorch_pretrained_bert import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAb1kCdVmeJc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import init\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFizI8b4lx7n"
      },
      "source": [
        "### **Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh0WA3QwliOE"
      },
      "outputs": [],
      "source": [
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "ASPECT = '<aspect>'\n",
        "\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "ASPECT_INDEX = 2\n",
        "\n",
        "INF = 1e9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed8jTmFBnjaQ",
        "outputId": "2fdba6e2-3ab0-4fd3-a81f-02c33b10349f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1271544.46B/s]\n"
          ]
        }
      ],
      "source": [
        "url = re.compile('(<url>.*</url>)')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VR_mYQnW6Y"
      },
      "source": [
        "# **CLASSES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeyPMH8aoLds"
      },
      "source": [
        "### **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ClXbYaUdL3O"
      },
      "outputs": [],
      "source": [
        "class ABSADataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, input_list):\n",
        "        super(ABSADataset, self).__init__()\n",
        "        data = np.load(path)\n",
        "        self.data = {}\n",
        "        for key, value in data.items():\n",
        "            self.data[key] = torch.tensor(value).long()\n",
        "        self.len = self.data['label'].size(0)\n",
        "        self.input_list = input_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return_value = []\n",
        "        for input in self.input_list:\n",
        "            return_value.append(self.data[input][index])\n",
        "        return_value.append(self.data['label'][index])\n",
        "        return return_value\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI3e2ErfdL2_"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self._count_dict = dict()\n",
        "        self._predefined_list = [PAD, UNK, ASPECT]\n",
        "\n",
        "    def add(self, word):\n",
        "        if word in self._count_dict:\n",
        "            self._count_dict[word] += 1\n",
        "        else:\n",
        "            self._count_dict[word] = 1\n",
        "\n",
        "    def add_list(self, words):\n",
        "        for word in words:\n",
        "            self.add(word)\n",
        "\n",
        "    def get_vocab(self, max_size=None, min_freq=0):\n",
        "        sorted_words = sorted(self._count_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
        "        word2index = {}\n",
        "        for word in self._predefined_list:\n",
        "            word2index[word] = len(word2index)\n",
        "        for word, freq in sorted_words:\n",
        "            if word in word2index:\n",
        "                continue\n",
        "            if (max_size is not None and len(word2index) >= max_size) or freq < min_freq:\n",
        "                word2index[word] = word2index[UNK]\n",
        "            else:\n",
        "                word2index[word] = len(word2index)\n",
        "        index2word = {}\n",
        "        index2word[word2index[UNK]] = UNK\n",
        "        for word, index in word2index.items():\n",
        "            if index == word2index[UNK]:\n",
        "                continue\n",
        "            else:\n",
        "                index2word[index] = word\n",
        "        return word2index, index2word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6GHzgVToQtT"
      },
      "source": [
        "### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8tMkZaYdL3L"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    The base class of attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout):\n",
        "        super(Attention, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, query_size) or FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        value: FloatTensor (batch_size, time_step, hidden_size)\n",
        "        mask: ByteTensor (batch_size, time_step) or ByteTensor (batch_size, num_queries, time_step)\n",
        "        \"\"\"\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key) # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        output = weights.matmul(value)\n",
        "        if single_query:\n",
        "            output = output.squeeze(1)\n",
        "        return output\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        raise NotImplementedError('Attention score method is not implemented.')\n",
        "\n",
        "    def _weights_normalize(self, score, mask):\n",
        "        if not mask is None:\n",
        "            score = score.masked_fill(mask == 0, -INF)\n",
        "        weights = F.softmax(score, dim=-1)\n",
        "        return weights\n",
        "\n",
        "    def get_attention_weights(self, query, key, mask=None):\n",
        "        single_query = False\n",
        "        if len(query.size()) == 2:\n",
        "            query = query.unsqueeze(1)\n",
        "            single_query = True\n",
        "        if mask is not None:\n",
        "            if len(mask.size()) == 2:\n",
        "                mask = mask.unsqueeze(1)\n",
        "            else:\n",
        "                assert mask.size(1) == query.size(1)\n",
        "        score = self._score(query, key)  # FloatTensor (batch_size, num_queries, time_step)\n",
        "        weights = self._weights_normalize(score, mask)\n",
        "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
        "        if single_query:\n",
        "            weights = weights.squeeze(1)\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr96dasjdL3M"
      },
      "outputs": [],
      "source": [
        "class BilinearAttention(Attention):\n",
        "\n",
        "    def __init__(self, query_size, key_size, dropout=0):\n",
        "        super(BilinearAttention, self).__init__(dropout)\n",
        "        self.weights = nn.Parameter(torch.FloatTensor(query_size, key_size))\n",
        "        init.xavier_uniform_(self.weights)\n",
        "\n",
        "    def _score(self, query, key):\n",
        "        \"\"\"\n",
        "        query: FloatTensor (batch_size, num_queries, query_size)\n",
        "        key: FloatTensor (batch_size, time_step, key_size)\n",
        "        \"\"\"\n",
        "        score = query.matmul(self.weights).matmul(key.transpose(1, 2))\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD2EgGuhdL3N"
      },
      "outputs": [],
      "source": [
        "class BertCapsuleNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, bert_size, capsule_size, dropout, num_categories):\n",
        "        super(BertCapsuleNetwork, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.bert_size = bert_size\n",
        "        self.capsule_size = capsule_size\n",
        "        self.aspect_transform = nn.Sequential(\n",
        "            nn.Linear(bert_size, capsule_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.sentence_transform = nn.Sequential(\n",
        "            nn.Linear(bert_size, capsule_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.norm_attention = BilinearAttention(capsule_size, capsule_size)\n",
        "        self.guide_capsule = nn.Parameter(\n",
        "            torch.Tensor(num_categories, capsule_size)\n",
        "        )\n",
        "        self.guide_weight = nn.Parameter(\n",
        "            torch.Tensor(capsule_size, capsule_size)\n",
        "        )\n",
        "        self.scale = nn.Parameter(torch.tensor(5.0))\n",
        "        self.capsule_projection = nn.Linear(bert_size, bert_size * num_categories)\n",
        "        self.dropout = dropout\n",
        "        self.num_categories = num_categories\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        init.xavier_uniform_(self.guide_capsule)\n",
        "        init.xavier_uniform_(self.guide_weight)\n",
        "\n",
        "    def load_sentiment(self, path):\n",
        "        sentiment = np.load(path)\n",
        "        e1 = np.mean(sentiment)\n",
        "        d1 = np.std(sentiment)\n",
        "        e2 = 0\n",
        "        d2 = np.sqrt(2.0 / (sentiment.shape[0] + sentiment.shape[1]))\n",
        "        sentiment = (sentiment - e1) / d1 * d2 + e2\n",
        "        self.guide_capsule.data.copy_(torch.tensor(sentiment))\n",
        "\n",
        "    def forward(self, bert_token, bert_segment):\n",
        "        # BERT encoding\n",
        "        encoder_layer, _ = self.bert(bert_token, bert_segment, output_all_encoded_layers=False)\n",
        "        batch_size, segment_len = bert_segment.size()\n",
        "        max_segment_len = bert_segment.argmax(dim=-1, keepdim=True)\n",
        "        batch_arrange = torch.arange(segment_len).unsqueeze(0).expand(batch_size, segment_len).to(bert_segment.device)\n",
        "        segment_mask = batch_arrange <= max_segment_len\n",
        "        sentence_mask = segment_mask & (1 - bert_segment).byte()\n",
        "        aspect_mask = bert_segment\n",
        "        sentence_lens = sentence_mask.long().sum(dim=1, keepdim=True)\n",
        "        # aspect average pooling\n",
        "        aspect_lens = aspect_mask.long().sum(dim=1, keepdim=True)\n",
        "        aspect = encoder_layer.masked_fill(aspect_mask.unsqueeze(-1) == 0, 0)\n",
        "        aspect = aspect.sum(dim=1, keepdim=False) / aspect_lens.float()\n",
        "        # sentence encode layer\n",
        "        max_len = sentence_lens.max().item()\n",
        "        sentence = encoder_layer[:, 0: max_len].contiguous()\n",
        "        sentence_mask = sentence_mask[:, 0: max_len].contiguous()\n",
        "        sentence = sentence.masked_fill(sentence_mask.unsqueeze(-1) == 0, 0)\n",
        "        # primary capsule layer\n",
        "        sentence = self.sentence_transform(sentence)\n",
        "        primary_capsule = squash(sentence, dim=-1)\n",
        "        aspect = self.aspect_transform(aspect)\n",
        "        aspect_capsule = squash(aspect, dim=-1)\n",
        "        # aspect aware normalization\n",
        "        norm_weight = self.norm_attention.get_attention_weights(aspect_capsule, primary_capsule, sentence_mask)\n",
        "        # capsule guided routing\n",
        "        category_capsule = self._capsule_guided_routing(primary_capsule, norm_weight)\n",
        "        category_capsule_norm = torch.sqrt(torch.sum(category_capsule * category_capsule, dim=-1, keepdim=False))\n",
        "        return category_capsule_norm\n",
        "\n",
        "    def _capsule_guided_routing(self, primary_capsule, norm_weight):\n",
        "        guide_capsule = squash(self.guide_capsule)\n",
        "        guide_matrix = primary_capsule.matmul(self.guide_weight).matmul(guide_capsule.transpose(0, 1))\n",
        "        guide_matrix = F.softmax(guide_matrix, dim=-1)\n",
        "        guide_matrix = guide_matrix * norm_weight.unsqueeze(-1) * self.scale  # (batch_size, time_step, num_categories)\n",
        "        category_capsule = guide_matrix.transpose(1, 2).matmul(primary_capsule)\n",
        "        category_capsule = F.dropout(category_capsule, p=self.dropout, training=self.training)\n",
        "        category_capsule = squash(category_capsule)\n",
        "        return category_capsule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm5pPZ4IdL3O"
      },
      "outputs": [],
      "source": [
        "class CapsuleLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, smooth=0.1, lamda=0.6):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.lamda = lamda\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        one_hot = torch.zeros_like(input).to(input.device)\n",
        "        one_hot = one_hot.scatter(1, target.unsqueeze(-1), 1)\n",
        "        a = torch.max(torch.zeros_like(input).to(input.device), 1 - self.smooth - input)\n",
        "        b = torch.max(torch.zeros_like(input).to(input.device), input - self.smooth)\n",
        "        loss = one_hot * a * a + self.lamda * (1 - one_hot) * b * b\n",
        "        loss = loss.sum(dim=1, keepdim=False)\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zUocDDn_J8"
      },
      "source": [
        "# **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qibh7tV9dL3B"
      },
      "outputs": [],
      "source": [
        "def parse_sentence_term(path, lowercase=False):\n",
        "    tree = parse(path)\n",
        "    sentences = tree.getroot()\n",
        "    data = []\n",
        "    split_char = '__split__'\n",
        "    for sentence in sentences:\n",
        "        text = sentence.find('text')\n",
        "        if text is None:\n",
        "            continue\n",
        "        text = text.text\n",
        "        if lowercase:\n",
        "            text = text.lower()\n",
        "        aspectTerms = sentence.find('aspectTerms')\n",
        "        if aspectTerms is None:\n",
        "            continue\n",
        "        for aspectTerm in aspectTerms:\n",
        "            term = aspectTerm.get('term')\n",
        "            if lowercase:\n",
        "                term = term.lower()\n",
        "            polarity = aspectTerm.get('polarity')\n",
        "            start = aspectTerm.get('from')\n",
        "            end = aspectTerm.get('to')\n",
        "            piece = text + split_char + term + split_char + polarity + split_char + start + split_char + end\n",
        "            data.append(piece)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXdUqmP3dL3D"
      },
      "outputs": [],
      "source": [
        "def category_filter(data, remove_list):\n",
        "    remove_set = set(remove_list)\n",
        "    filtered_data = []\n",
        "    for text in data:\n",
        "        if not text.split('__split__')[2] in remove_set:\n",
        "            filtered_data.append(text)\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DndCoFiRnduh"
      },
      "outputs": [],
      "source": [
        "def check(x):\n",
        "    return len(x) >= 1 and not x.isspace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxke1zzhne82"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    tokens = [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
        "    return list(filter(check, tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNavxTnmngNP"
      },
      "outputs": [],
      "source": [
        "def build_vocab(data, max_size, min_freq):\n",
        "    if max_size == 'None':\n",
        "        max_size = None\n",
        "    vocab = Vocab()\n",
        "    for piece in data:\n",
        "        text = piece.split('__split__')[0]\n",
        "        text = tokenizer(text)\n",
        "        vocab.add_list(text)\n",
        "    return vocab.get_vocab(max_size=max_size, min_freq=min_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIdJFNQvdL3F"
      },
      "outputs": [],
      "source": [
        "def save_term_data(data, word2index, path):\n",
        "    dirname = os.path.dirname(path)\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "    sentence = []\n",
        "    aspect = []\n",
        "    label = []\n",
        "    context = []\n",
        "    bert_token = []\n",
        "    bert_segment = []\n",
        "    td_left = []\n",
        "    td_right = []\n",
        "    f = lambda x: word2index[x] if x in word2index else word2index[UNK]\n",
        "    g = lambda x: list(map(f, tokenizer(x)))\n",
        "    d = {\n",
        "        'positive': 0,\n",
        "        'negative': 1,\n",
        "        'neutral': 2,\n",
        "        'conflict': 3\n",
        "    }\n",
        "    for piece in data:\n",
        "        text, term, polarity, start, end = piece.split('__split__')\n",
        "        start, end = int(start), int(end)\n",
        "        assert text[start: end] == term\n",
        "        sentence.append(g(text))\n",
        "        aspect.append(g(term))\n",
        "        label.append(d[polarity])\n",
        "        left_part = g(text[:start])\n",
        "        right_part = g(text[end:])\n",
        "        context.append(left_part + [ASPECT_INDEX] + right_part)\n",
        "        bert_sentence = bert_tokenizer.tokenize(text)\n",
        "        bert_aspect = bert_tokenizer.tokenize(term)\n",
        "        bert_token.append(bert_tokenizer.convert_tokens_to_ids(['[CLS]'] + bert_sentence + ['[SEP]'] + bert_aspect + ['[SEP]']))\n",
        "        bert_segment.append([0] * (len(bert_sentence) + 2) + [1] * (len(bert_aspect) + 1))\n",
        "        td_left.append(g(text[:end]))\n",
        "        td_right.append(g(text[start:])[::-1])\n",
        "        assert len(bert_token[-1]) == len(bert_segment[-1])\n",
        "    max_length = lambda x: max([len(y) for y in x])\n",
        "    sentence_max_len = max_length(sentence)\n",
        "    aspect_max_len = max_length(aspect)\n",
        "    context_max_len = max_length(context)\n",
        "    bert_max_len = max_length(bert_token)\n",
        "    td_left_max_len = max_length(td_left)\n",
        "    td_right_max_len = max_length(td_right)\n",
        "    num = len(data)\n",
        "    for i in range(num):\n",
        "        sentence[i].extend([0] * (sentence_max_len - len(sentence[i])))\n",
        "        aspect[i].extend([0] * (aspect_max_len - len(aspect[i])))\n",
        "        context[i].extend([0] * (context_max_len - len(context[i])))\n",
        "        bert_token[i].extend([0] * (bert_max_len - len(bert_token[i])))\n",
        "        bert_segment[i].extend([0] * (bert_max_len - len(bert_segment[i])))\n",
        "        td_left[i].extend([0] * (td_left_max_len - len(td_left[i])))\n",
        "        td_right[i].extend([0] * (td_right_max_len - len(td_right[i])))\n",
        "    sentence = np.asarray(sentence, dtype=np.int32)\n",
        "    aspect = np.asarray(aspect, dtype=np.int32)\n",
        "    label = np.asarray(label, dtype=np.int32)\n",
        "    context = np.asarray(context, dtype=np.int32)\n",
        "    bert_token = np.asarray(bert_token, dtype=np.int32)\n",
        "    bert_segment = np.asarray(bert_segment, dtype=np.int32)\n",
        "    td_left = np.asarray(td_left, dtype=np.int32)\n",
        "    td_right = np.asarray(td_right, dtype=np.int32)\n",
        "    np.savez(path, sentence=sentence, aspect=aspect, label=label, context=context, bert_token=bert_token, bert_segment=bert_segment,\n",
        "             td_left=td_left, td_right=td_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9mXiH6SdL3I"
      },
      "outputs": [],
      "source": [
        "def load_sentiment_matrix(glove_path, sentiment_path):\n",
        "    sentiment_matrix = np.zeros((3, 300), dtype=np.float32)\n",
        "    sd = json.load(open(sentiment_path, 'r', encoding='utf-8'))\n",
        "    sd['positive'] = set(sd['positive'])\n",
        "    sd['negative'] = set(sd['negative'])\n",
        "    sd['neutral'] = set(sd['neutral'])\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            word = content[0]\n",
        "            vec = np.array(list(map(float, content[1:])))\n",
        "            if word in sd['positive']:\n",
        "                sentiment_matrix[0] += vec\n",
        "            elif word in sd['negative']:\n",
        "                sentiment_matrix[1] += vec\n",
        "            elif word in sd['neutral']:\n",
        "                sentiment_matrix[2] += vec\n",
        "    sentiment_matrix -= sentiment_matrix.mean()\n",
        "    sentiment_matrix = sentiment_matrix / sentiment_matrix.std() * np.sqrt(2.0 / (300.0 + 3.0))\n",
        "    return sentiment_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_9sUTDrdL3J"
      },
      "outputs": [],
      "source": [
        "def analyze_term(data):\n",
        "    num = len(data)\n",
        "    sentence_lens = []\n",
        "    aspect_lens = []\n",
        "    log = {'total': num}\n",
        "    for piece in data:\n",
        "        text, term, polarity, _, _ = piece.split('__split__')\n",
        "        sentence_lens.append(len(tokenizer(text)))\n",
        "        aspect_lens.append(len(tokenizer(term)))\n",
        "        if not polarity in log:\n",
        "            log[polarity] = 0\n",
        "        log[polarity] += 1\n",
        "    log['sentence_max_len'] = max(sentence_lens)\n",
        "    log['sentence_avg_len'] = sum(sentence_lens) / len(sentence_lens)\n",
        "    log['aspect_max_len'] = max(aspect_lens)\n",
        "    log['aspect_avg_len'] = sum(aspect_lens) / len(aspect_lens)\n",
        "    return log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHOvLH3wdL3K"
      },
      "outputs": [],
      "source": [
        "def sentence_clip(sentence):\n",
        "    mask = (sentence != PAD_INDEX)\n",
        "    sentence_lens = mask.long().sum(dim=1, keepdim=False)\n",
        "    max_len = sentence_lens.max().item()\n",
        "    return sentence[:, :max_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA0qo61ydL3K"
      },
      "outputs": [],
      "source": [
        "def squash(x, dim=-1):\n",
        "    squared = torch.sum(x * x, dim=dim, keepdim=True)\n",
        "    scale = torch.sqrt(squared) / (1.0 + squared)\n",
        "    return scale * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpOafbYKdL3P"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    base_path = os.path.join(config['base_path'])\n",
        "    log_path = os.path.join(base_path, 'log/log.yml')\n",
        "    log = yaml.safe_load(open(log_path))\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model = BertCapsuleNetwork(\n",
        "        bert=bert,\n",
        "        bert_size=config2['bert_size'],\n",
        "        capsule_size=config2['capsule_size'],\n",
        "        dropout=config2['dropout'],\n",
        "        num_categories=log['num_categories']\n",
        "    )\n",
        "    model.load_sentiment(os.path.join(base_path, 'processed/sentiment_matrix.npy'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6MxubyGdL3P"
      },
      "outputs": [],
      "source": [
        "def make_term_data():\n",
        "    base_path = config['base_path']\n",
        "    train_path = os.path.join(base_path, 'processed/train.npz')\n",
        "    val_path = os.path.join(base_path, 'processed/val.npz')\n",
        "    train_data = ABSADataset(train_path, ['bert_token', 'bert_segment'])\n",
        "    val_data = ABSADataset(val_path, ['bert_token', 'bert_segment'])\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_data,\n",
        "        batch_size=config2['batch_size'],\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMlnUPFBdL3Q"
      },
      "outputs": [],
      "source": [
        "def make_optimizer(model):\n",
        "    lr = config2['learning_rate']\n",
        "    weight_decay = config2['weight_decay']\n",
        "    opt = {\n",
        "        'sgd': optim.SGD,\n",
        "        'adadelta': optim.Adadelta,\n",
        "        'adam': optim.Adam,\n",
        "        'adamax': optim.Adamax,\n",
        "        'adagrad': optim.Adagrad,\n",
        "        'asgd': optim.ASGD,\n",
        "        'rmsprop': optim.RMSprop,\n",
        "        'adabound': adabound.AdaBound\n",
        "    }\n",
        "    if 'momentum' in config:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay, momentum=config2['momentum'])\n",
        "    else:\n",
        "        optimizer = opt[config2['optimizer']](model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdlmWNmEomRD"
      },
      "outputs": [],
      "source": [
        "def eval(model, data_loader, criterion=None):\n",
        "    total_samples = 0\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label).item() if criterion is not None else 0\n",
        "            total_samples += input0.size(0)\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            total_loss += loss * input0.size(0)\n",
        "    accuracy = correct_samples / total_samples\n",
        "    avg_loss = total_loss / total_samples\n",
        "    if criterion is not None:\n",
        "        return accuracy, avg_loss\n",
        "    else:\n",
        "        return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAbKjs4wjARE"
      },
      "outputs": [],
      "source": [
        "def load_glove(path, vocab_size, word2index):\n",
        "    if not os.path.isfile(path):\n",
        "        raise IOError('Not a file', path)\n",
        "    glove = np.random.uniform(-0.01, 0.01, [vocab_size, 300])\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            content = line.split(' ')\n",
        "            if content[0] in word2index:\n",
        "                glove[word2index[content[0]]] = np.array(list(map(float, content[1:])))\n",
        "    glove[PAD_INDEX, :] = 0\n",
        "    return glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhYTiEFedL3U"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "    train_data = parse_sentence_term(config['raw_train_path'], lowercase=config['lowercase'])\n",
        "    val_data = parse_sentence_term(config['raw_val_path'], lowercase=config['lowercase'])\n",
        "    test_data = parse_sentence_term(config['raw_test_path'], lowercase=config['lowercase'])\n",
        "\n",
        "    remove_list = ['conflict']\n",
        "    train_data = category_filter(train_data, remove_list)\n",
        "    val_data = category_filter(val_data, remove_list)\n",
        "    test_data = category_filter(test_data, remove_list)\n",
        "\n",
        "    word2index, index2word = build_vocab(train_data, max_size=config['max_vocab_size'], min_freq=config['min_vocab_freq'])\n",
        "\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'processed')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'processed'))\n",
        "            \n",
        "    save_term_data(train_data, word2index, os.path.join(config[\"base_path\"], 'processed/train.npz'))\n",
        "    save_term_data(val_data, word2index, os.path.join(config[\"base_path\"], 'processed/val.npz'))\n",
        "    save_term_data(test_data, word2index, os.path.join(config[\"base_path\"], 'processed/test.npz'))\n",
        "\n",
        "    glove = load_glove(config['glove_path'], len(index2word), word2index)\n",
        "\n",
        "    sentiment_matrix = load_sentiment_matrix(config['glove_path'], config['sentiment_path'])\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/glove.npy'), glove)\n",
        "    np.save(os.path.join(config[\"base_path\"], 'processed/sentiment_matrix.npy'), sentiment_matrix)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/word2index.pickle'), 'wb') as handle:\n",
        "        pickle.dump(word2index, handle)\n",
        "    with open(os.path.join(config[\"base_path\"], 'processed/index2word.pickle'), 'wb') as handle:\n",
        "        pickle.dump(index2word, handle)\n",
        "    analyze = analyze_term\n",
        "    log = {\n",
        "        'vocab_size': len(index2word),\n",
        "        'oov_size': len(word2index) - len(index2word),\n",
        "        'train_data': analyze(train_data),\n",
        "        'val_data': analyze(val_data),\n",
        "        'test_data': analyze(test_data),\n",
        "        'num_categories': 3\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(os.path.join(config[\"base_path\"], 'log')):\n",
        "        os.makedirs(os.path.join(config[\"base_path\"], 'log'))\n",
        "    with open(os.path.join(config[\"base_path\"], 'log/log.yml'), 'w') as handle:\n",
        "        yaml.safe_dump(log, handle, encoding='utf-8', allow_unicode=True, default_flow_style=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQS3yFtDdL3Q"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    train_loader, val_loader = make_term_data()\n",
        "    global model\n",
        "    model = model.cuda()\n",
        "    base_path = config['base_path']\n",
        "    model_path = os.path.join(base_path, 'checkpoints/%s.pth' % \"bert_capsnet\")\n",
        "    if not os.path.exists(os.path.dirname(model_path)):\n",
        "        os.makedirs(os.path.dirname(model_path))\n",
        "    with open(os.path.join(base_path, 'processed/index2word.pickle'), 'rb') as handle:\n",
        "        index2word = pickle.load(handle)\n",
        "    criterion = CapsuleLoss()\n",
        "    optimizer = make_optimizer(model)\n",
        "    max_val_accuracy = 0\n",
        "    min_val_loss = 100\n",
        "    global_step = 0\n",
        "    \n",
        "    for epoch in range(config2['num_epoches']):\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        correct_samples = 0\n",
        "        start = time.time()\n",
        "        for i, data in enumerate(train_loader):\n",
        "            global_step += 1\n",
        "            model.train()\n",
        "            input0, input1, label = data\n",
        "            input0, input1, label = input0.cuda(), input1.cuda(), label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            logit = model(input0, input1)\n",
        "            loss = criterion(logit, label)\n",
        "            batch_size = input0.size(0)\n",
        "            total_loss += batch_size * loss.item()\n",
        "            total_samples += batch_size\n",
        "            pred = logit.argmax(dim=1)\n",
        "            correct_samples += (label == pred).long().sum().item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "            if i % 10 == 0 and i > 0:\n",
        "                train_loss = total_loss / total_samples\n",
        "                train_accuracy = correct_samples / total_samples\n",
        "                total_loss = 0\n",
        "                total_samples = 0\n",
        "                correct_samples = 0\n",
        "                val_accuracy, val_loss = eval(model, val_loader, criterion)\n",
        "                print('[epoch %2d] [step %3d] train_loss: %.4f train_acc: %.4f val_loss: %.4f val_acc: %.4f'\n",
        "                      % (epoch, i, train_loss, train_accuracy, val_loss, val_accuracy))\n",
        "                if val_accuracy > max_val_accuracy:\n",
        "                    max_val_accuracy = val_accuracy\n",
        "                    # torch.save(aspect_term_model.state_dict(), model_path)\n",
        "                if val_loss < min_val_loss:\n",
        "                    min_val_loss = val_loss\n",
        "                    if epoch > 0:\n",
        "                        torch.save(model.state_dict(), model_path)\n",
        "        end = time.time()\n",
        "        print('time: %.4fs' % (end - start))\n",
        "    print('max_val_accuracy:', max_val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4rZNufDpQNi"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as9UA-0NtyNS"
      },
      "source": [
        "### **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "conAL_dUdL3R"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"base_path\": \"drive/MyDrive/CS4248/MAMS-ATSA\",\n",
        "    \"mode\": \"term\",\n",
        "    \"glove_path\": \"drive/MyDrive/CS4248/glove.42B.300d.txt\",\n",
        "    \"sentiment_path\": \"drive/MyDrive/CS4248/sentiment_dict.json\",\n",
        "    \"max_vocab_size\": None,\n",
        "    \"min_vocab_freq\": 0,\n",
        "    \"lowercase\": True\n",
        "    }\n",
        "\n",
        "config[\"raw_train_path\"] = os.path.join(config[\"base_path\"], 'raw/train.xml')\n",
        "config[\"raw_val_path\"] = os.path.join(config[\"base_path\"], 'raw/val.xml')\n",
        "config[\"raw_test_path\"] = os.path.join(config['base_path'], 'raw/test.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0XX1iK3owFD"
      },
      "outputs": [],
      "source": [
        "config2 = {\n",
        "    'bert_size': 768,\n",
        "    'capsule_size': 300,\n",
        "    'dropout': 0.1,\n",
        "    'optimizer': 'adam',\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.00002,\n",
        "    'weight_decay': 0,\n",
        "    'num_epoches': 5,\n",
        "    'gpu': 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOXozd3t573"
      },
      "source": [
        "### **Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjQxMzYWpzrt"
      },
      "outputs": [],
      "source": [
        "preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay3c-MAfdL3W",
        "outputId": "95868c43-b5a2-4bde-fa49-06d232ea3cec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:10<00:00, 40097258.55B/s]\n"
          ]
        }
      ],
      "source": [
        "model = make_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK0iM2ZZdL3W",
        "outputId": "26c57f19-d5d2-4bd5-9a9d-85c2ea214a56",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[epoch  0] [step  10] train_loss: 0.3446 train_acc: 0.4176 val_loss: 0.3401 val_acc: 0.4535\n",
            "[epoch  0] [step  20] train_loss: 0.3389 train_acc: 0.4469 val_loss: 0.3365 val_acc: 0.4535\n",
            "[epoch  0] [step  30] train_loss: 0.3378 train_acc: 0.4406 val_loss: 0.3349 val_acc: 0.4535\n",
            "[epoch  0] [step  40] train_loss: 0.3352 train_acc: 0.4375 val_loss: 0.3319 val_acc: 0.4535\n",
            "[epoch  0] [step  50] train_loss: 0.3362 train_acc: 0.4313 val_loss: 0.3292 val_acc: 0.4535\n",
            "[epoch  0] [step  60] train_loss: 0.3308 train_acc: 0.4531 val_loss: 0.3260 val_acc: 0.4542\n",
            "[epoch  0] [step  70] train_loss: 0.3272 train_acc: 0.4562 val_loss: 0.3235 val_acc: 0.5180\n",
            "[epoch  0] [step  80] train_loss: 0.3205 train_acc: 0.5344 val_loss: 0.3092 val_acc: 0.5495\n",
            "[epoch  0] [step  90] train_loss: 0.3087 train_acc: 0.5813 val_loss: 0.3025 val_acc: 0.5616\n",
            "[epoch  0] [step 100] train_loss: 0.3064 train_acc: 0.5500 val_loss: 0.2991 val_acc: 0.5398\n",
            "[epoch  0] [step 110] train_loss: 0.2960 train_acc: 0.5656 val_loss: 0.2871 val_acc: 0.5698\n",
            "[epoch  0] [step 120] train_loss: 0.2909 train_acc: 0.5563 val_loss: 0.2833 val_acc: 0.5736\n",
            "[epoch  0] [step 130] train_loss: 0.2859 train_acc: 0.5500 val_loss: 0.2822 val_acc: 0.5578\n",
            "[epoch  0] [step 140] train_loss: 0.2869 train_acc: 0.5625 val_loss: 0.2767 val_acc: 0.5841\n",
            "[epoch  0] [step 150] train_loss: 0.2664 train_acc: 0.6031 val_loss: 0.2701 val_acc: 0.5931\n",
            "[epoch  0] [step 160] train_loss: 0.2709 train_acc: 0.6062 val_loss: 0.2635 val_acc: 0.6329\n",
            "[epoch  0] [step 170] train_loss: 0.2700 train_acc: 0.6250 val_loss: 0.2657 val_acc: 0.5916\n",
            "[epoch  0] [step 180] train_loss: 0.2639 train_acc: 0.6000 val_loss: 0.2632 val_acc: 0.6021\n",
            "[epoch  0] [step 190] train_loss: 0.2650 train_acc: 0.5844 val_loss: 0.2572 val_acc: 0.6156\n",
            "[epoch  0] [step 200] train_loss: 0.2822 train_acc: 0.5500 val_loss: 0.2570 val_acc: 0.6479\n",
            "[epoch  0] [step 210] train_loss: 0.2678 train_acc: 0.6000 val_loss: 0.2497 val_acc: 0.6276\n",
            "[epoch  0] [step 220] train_loss: 0.2590 train_acc: 0.6438 val_loss: 0.2500 val_acc: 0.6261\n",
            "[epoch  0] [step 230] train_loss: 0.2484 train_acc: 0.6406 val_loss: 0.2480 val_acc: 0.6261\n",
            "[epoch  0] [step 240] train_loss: 0.2468 train_acc: 0.6469 val_loss: 0.2419 val_acc: 0.6614\n",
            "[epoch  0] [step 250] train_loss: 0.2484 train_acc: 0.6344 val_loss: 0.2357 val_acc: 0.6839\n",
            "[epoch  0] [step 260] train_loss: 0.2427 train_acc: 0.6813 val_loss: 0.2286 val_acc: 0.6982\n",
            "[epoch  0] [step 270] train_loss: 0.2478 train_acc: 0.6813 val_loss: 0.2260 val_acc: 0.7335\n",
            "[epoch  0] [step 280] train_loss: 0.2314 train_acc: 0.7031 val_loss: 0.2157 val_acc: 0.7515\n",
            "[epoch  0] [step 290] train_loss: 0.2388 train_acc: 0.6813 val_loss: 0.2107 val_acc: 0.7312\n",
            "[epoch  0] [step 300] train_loss: 0.2351 train_acc: 0.6875 val_loss: 0.2054 val_acc: 0.7470\n",
            "[epoch  0] [step 310] train_loss: 0.2292 train_acc: 0.7219 val_loss: 0.1978 val_acc: 0.7688\n",
            "[epoch  0] [step 320] train_loss: 0.1839 train_acc: 0.8031 val_loss: 0.1904 val_acc: 0.7650\n",
            "[epoch  0] [step 330] train_loss: 0.1827 train_acc: 0.7906 val_loss: 0.1867 val_acc: 0.7755\n",
            "[epoch  0] [step 340] train_loss: 0.1875 train_acc: 0.7719 val_loss: 0.1819 val_acc: 0.7830\n",
            "time: 484.5728s\n",
            "[epoch  1] [step  10] train_loss: 0.1847 train_acc: 0.7699 val_loss: 0.1792 val_acc: 0.7725\n",
            "[epoch  1] [step  20] train_loss: 0.1548 train_acc: 0.8250 val_loss: 0.1736 val_acc: 0.7815\n",
            "[epoch  1] [step  30] train_loss: 0.1595 train_acc: 0.8094 val_loss: 0.1723 val_acc: 0.7928\n",
            "[epoch  1] [step  40] train_loss: 0.1655 train_acc: 0.8063 val_loss: 0.1720 val_acc: 0.7823\n",
            "[epoch  1] [step  50] train_loss: 0.1546 train_acc: 0.8031 val_loss: 0.1721 val_acc: 0.7763\n",
            "[epoch  1] [step  60] train_loss: 0.1565 train_acc: 0.7937 val_loss: 0.1731 val_acc: 0.7800\n",
            "[epoch  1] [step  70] train_loss: 0.1460 train_acc: 0.8250 val_loss: 0.1770 val_acc: 0.7635\n",
            "[epoch  1] [step  80] train_loss: 0.1543 train_acc: 0.8031 val_loss: 0.1619 val_acc: 0.7928\n",
            "[epoch  1] [step  90] train_loss: 0.1545 train_acc: 0.7937 val_loss: 0.1629 val_acc: 0.7853\n",
            "[epoch  1] [step 100] train_loss: 0.1527 train_acc: 0.8063 val_loss: 0.1609 val_acc: 0.7950\n",
            "[epoch  1] [step 110] train_loss: 0.1336 train_acc: 0.8500 val_loss: 0.1605 val_acc: 0.7943\n",
            "[epoch  1] [step 120] train_loss: 0.1596 train_acc: 0.7906 val_loss: 0.1592 val_acc: 0.8048\n",
            "[epoch  1] [step 130] train_loss: 0.1436 train_acc: 0.8250 val_loss: 0.1653 val_acc: 0.7898\n",
            "[epoch  1] [step 140] train_loss: 0.1506 train_acc: 0.8063 val_loss: 0.1521 val_acc: 0.8056\n",
            "[epoch  1] [step 150] train_loss: 0.1547 train_acc: 0.8063 val_loss: 0.1515 val_acc: 0.8086\n",
            "[epoch  1] [step 160] train_loss: 0.1382 train_acc: 0.8344 val_loss: 0.1512 val_acc: 0.8063\n",
            "[epoch  1] [step 170] train_loss: 0.1337 train_acc: 0.8250 val_loss: 0.1511 val_acc: 0.8101\n",
            "[epoch  1] [step 180] train_loss: 0.1400 train_acc: 0.8219 val_loss: 0.1465 val_acc: 0.8161\n",
            "[epoch  1] [step 190] train_loss: 0.1559 train_acc: 0.7937 val_loss: 0.1479 val_acc: 0.8056\n",
            "[epoch  1] [step 200] train_loss: 0.1342 train_acc: 0.8250 val_loss: 0.1651 val_acc: 0.7830\n",
            "[epoch  1] [step 210] train_loss: 0.1448 train_acc: 0.8094 val_loss: 0.1577 val_acc: 0.7943\n",
            "[epoch  1] [step 220] train_loss: 0.1254 train_acc: 0.8531 val_loss: 0.1514 val_acc: 0.7980\n",
            "[epoch  1] [step 230] train_loss: 0.1321 train_acc: 0.8313 val_loss: 0.1489 val_acc: 0.8086\n",
            "[epoch  1] [step 240] train_loss: 0.1336 train_acc: 0.8219 val_loss: 0.1506 val_acc: 0.8116\n",
            "[epoch  1] [step 250] train_loss: 0.1227 train_acc: 0.8375 val_loss: 0.1484 val_acc: 0.8116\n",
            "[epoch  1] [step 260] train_loss: 0.1555 train_acc: 0.7906 val_loss: 0.1534 val_acc: 0.7980\n",
            "[epoch  1] [step 270] train_loss: 0.1600 train_acc: 0.7844 val_loss: 0.1526 val_acc: 0.7988\n",
            "[epoch  1] [step 280] train_loss: 0.1294 train_acc: 0.8313 val_loss: 0.1467 val_acc: 0.8123\n",
            "[epoch  1] [step 290] train_loss: 0.1298 train_acc: 0.8438 val_loss: 0.1541 val_acc: 0.7920\n",
            "[epoch  1] [step 300] train_loss: 0.1646 train_acc: 0.7812 val_loss: 0.1483 val_acc: 0.8003\n",
            "[epoch  1] [step 310] train_loss: 0.1335 train_acc: 0.8281 val_loss: 0.1481 val_acc: 0.8033\n",
            "[epoch  1] [step 320] train_loss: 0.1258 train_acc: 0.8281 val_loss: 0.1432 val_acc: 0.8168\n",
            "[epoch  1] [step 330] train_loss: 0.1100 train_acc: 0.8594 val_loss: 0.1528 val_acc: 0.7995\n",
            "[epoch  1] [step 340] train_loss: 0.1318 train_acc: 0.8406 val_loss: 0.1453 val_acc: 0.8198\n",
            "time: 504.8542s\n",
            "[epoch  2] [step  10] train_loss: 0.1007 train_acc: 0.8835 val_loss: 0.1511 val_acc: 0.8086\n",
            "[epoch  2] [step  20] train_loss: 0.0985 train_acc: 0.9000 val_loss: 0.1467 val_acc: 0.8168\n",
            "[epoch  2] [step  30] train_loss: 0.0920 train_acc: 0.8875 val_loss: 0.1468 val_acc: 0.8093\n",
            "[epoch  2] [step  40] train_loss: 0.0791 train_acc: 0.9094 val_loss: 0.1472 val_acc: 0.8123\n",
            "[epoch  2] [step  50] train_loss: 0.0843 train_acc: 0.9031 val_loss: 0.1481 val_acc: 0.8123\n",
            "[epoch  2] [step  60] train_loss: 0.1126 train_acc: 0.8688 val_loss: 0.1525 val_acc: 0.7980\n",
            "[epoch  2] [step  70] train_loss: 0.0943 train_acc: 0.8812 val_loss: 0.1465 val_acc: 0.8138\n",
            "[epoch  2] [step  80] train_loss: 0.0972 train_acc: 0.8875 val_loss: 0.1478 val_acc: 0.8123\n",
            "[epoch  2] [step  90] train_loss: 0.1072 train_acc: 0.8688 val_loss: 0.1533 val_acc: 0.7995\n",
            "[epoch  2] [step 100] train_loss: 0.0851 train_acc: 0.8969 val_loss: 0.1428 val_acc: 0.8258\n",
            "[epoch  2] [step 110] train_loss: 0.1238 train_acc: 0.8469 val_loss: 0.1499 val_acc: 0.8108\n",
            "[epoch  2] [step 120] train_loss: 0.0887 train_acc: 0.9031 val_loss: 0.1523 val_acc: 0.8116\n",
            "[epoch  2] [step 130] train_loss: 0.0832 train_acc: 0.9000 val_loss: 0.1523 val_acc: 0.8153\n",
            "[epoch  2] [step 140] train_loss: 0.1097 train_acc: 0.8594 val_loss: 0.1595 val_acc: 0.8048\n",
            "[epoch  2] [step 150] train_loss: 0.1034 train_acc: 0.8812 val_loss: 0.1472 val_acc: 0.8198\n",
            "[epoch  2] [step 160] train_loss: 0.0886 train_acc: 0.8875 val_loss: 0.1524 val_acc: 0.8086\n",
            "[epoch  2] [step 170] train_loss: 0.0864 train_acc: 0.8906 val_loss: 0.1522 val_acc: 0.8108\n",
            "[epoch  2] [step 180] train_loss: 0.0932 train_acc: 0.8781 val_loss: 0.1625 val_acc: 0.7958\n",
            "[epoch  2] [step 190] train_loss: 0.1061 train_acc: 0.8562 val_loss: 0.1445 val_acc: 0.8168\n",
            "[epoch  2] [step 200] train_loss: 0.0981 train_acc: 0.8750 val_loss: 0.1423 val_acc: 0.8168\n",
            "[epoch  2] [step 210] train_loss: 0.1007 train_acc: 0.8781 val_loss: 0.1479 val_acc: 0.8093\n",
            "[epoch  2] [step 220] train_loss: 0.0878 train_acc: 0.8812 val_loss: 0.1430 val_acc: 0.8206\n",
            "[epoch  2] [step 230] train_loss: 0.0874 train_acc: 0.8812 val_loss: 0.1450 val_acc: 0.8161\n",
            "[epoch  2] [step 240] train_loss: 0.0855 train_acc: 0.9031 val_loss: 0.1506 val_acc: 0.8176\n",
            "[epoch  2] [step 250] train_loss: 0.1139 train_acc: 0.8469 val_loss: 0.1425 val_acc: 0.8258\n",
            "[epoch  2] [step 260] train_loss: 0.1136 train_acc: 0.8594 val_loss: 0.1423 val_acc: 0.8161\n",
            "[epoch  2] [step 270] train_loss: 0.0778 train_acc: 0.9031 val_loss: 0.1417 val_acc: 0.8243\n",
            "[epoch  2] [step 280] train_loss: 0.1033 train_acc: 0.8594 val_loss: 0.1465 val_acc: 0.8168\n",
            "[epoch  2] [step 290] train_loss: 0.0750 train_acc: 0.9094 val_loss: 0.1420 val_acc: 0.8228\n",
            "[epoch  2] [step 300] train_loss: 0.0916 train_acc: 0.8688 val_loss: 0.1457 val_acc: 0.8191\n",
            "[epoch  2] [step 310] train_loss: 0.1034 train_acc: 0.8656 val_loss: 0.1440 val_acc: 0.8236\n",
            "[epoch  2] [step 320] train_loss: 0.0842 train_acc: 0.8969 val_loss: 0.1536 val_acc: 0.8161\n",
            "[epoch  2] [step 330] train_loss: 0.0987 train_acc: 0.8781 val_loss: 0.1445 val_acc: 0.8161\n",
            "[epoch  2] [step 340] train_loss: 0.1084 train_acc: 0.8562 val_loss: 0.1423 val_acc: 0.8296\n",
            "time: 489.4093s\n",
            "[epoch  3] [step  10] train_loss: 0.0742 train_acc: 0.9176 val_loss: 0.1394 val_acc: 0.8281\n",
            "[epoch  3] [step  20] train_loss: 0.0505 train_acc: 0.9469 val_loss: 0.1413 val_acc: 0.8251\n",
            "[epoch  3] [step  30] train_loss: 0.0554 train_acc: 0.9313 val_loss: 0.1487 val_acc: 0.8161\n",
            "[epoch  3] [step  40] train_loss: 0.0591 train_acc: 0.9250 val_loss: 0.1535 val_acc: 0.8191\n",
            "[epoch  3] [step  50] train_loss: 0.0806 train_acc: 0.9094 val_loss: 0.1553 val_acc: 0.8116\n",
            "[epoch  3] [step  60] train_loss: 0.0654 train_acc: 0.9219 val_loss: 0.1474 val_acc: 0.8183\n",
            "[epoch  3] [step  70] train_loss: 0.0646 train_acc: 0.9281 val_loss: 0.1508 val_acc: 0.8176\n",
            "[epoch  3] [step  80] train_loss: 0.0575 train_acc: 0.9406 val_loss: 0.1505 val_acc: 0.8221\n",
            "[epoch  3] [step  90] train_loss: 0.0521 train_acc: 0.9437 val_loss: 0.1569 val_acc: 0.8138\n",
            "[epoch  3] [step 100] train_loss: 0.0745 train_acc: 0.9094 val_loss: 0.1429 val_acc: 0.8318\n",
            "[epoch  3] [step 110] train_loss: 0.0656 train_acc: 0.9219 val_loss: 0.1501 val_acc: 0.8138\n",
            "[epoch  3] [step 120] train_loss: 0.0594 train_acc: 0.9187 val_loss: 0.1482 val_acc: 0.8191\n",
            "[epoch  3] [step 130] train_loss: 0.0699 train_acc: 0.9187 val_loss: 0.1429 val_acc: 0.8363\n",
            "[epoch  3] [step 140] train_loss: 0.0484 train_acc: 0.9531 val_loss: 0.1507 val_acc: 0.8206\n",
            "[epoch  3] [step 150] train_loss: 0.0782 train_acc: 0.9000 val_loss: 0.1521 val_acc: 0.8168\n",
            "[epoch  3] [step 160] train_loss: 0.0589 train_acc: 0.9375 val_loss: 0.1541 val_acc: 0.8198\n",
            "[epoch  3] [step 170] train_loss: 0.0615 train_acc: 0.9187 val_loss: 0.1541 val_acc: 0.8221\n",
            "[epoch  3] [step 180] train_loss: 0.0558 train_acc: 0.9250 val_loss: 0.1528 val_acc: 0.8206\n",
            "[epoch  3] [step 190] train_loss: 0.0605 train_acc: 0.9250 val_loss: 0.1512 val_acc: 0.8236\n",
            "[epoch  3] [step 200] train_loss: 0.0583 train_acc: 0.9250 val_loss: 0.1491 val_acc: 0.8198\n",
            "[epoch  3] [step 210] train_loss: 0.0661 train_acc: 0.9250 val_loss: 0.1490 val_acc: 0.8213\n",
            "[epoch  3] [step 220] train_loss: 0.0622 train_acc: 0.9281 val_loss: 0.1496 val_acc: 0.8258\n",
            "[epoch  3] [step 230] train_loss: 0.0579 train_acc: 0.9156 val_loss: 0.1460 val_acc: 0.8251\n",
            "[epoch  3] [step 240] train_loss: 0.0682 train_acc: 0.9219 val_loss: 0.1499 val_acc: 0.8213\n",
            "[epoch  3] [step 250] train_loss: 0.0668 train_acc: 0.9062 val_loss: 0.1585 val_acc: 0.8078\n",
            "[epoch  3] [step 260] train_loss: 0.0575 train_acc: 0.9313 val_loss: 0.1479 val_acc: 0.8191\n",
            "[epoch  3] [step 270] train_loss: 0.0715 train_acc: 0.9125 val_loss: 0.1551 val_acc: 0.8116\n",
            "[epoch  3] [step 280] train_loss: 0.0802 train_acc: 0.9094 val_loss: 0.1526 val_acc: 0.8071\n",
            "[epoch  3] [step 290] train_loss: 0.0608 train_acc: 0.9313 val_loss: 0.1487 val_acc: 0.8213\n",
            "[epoch  3] [step 300] train_loss: 0.0867 train_acc: 0.8906 val_loss: 0.1524 val_acc: 0.8168\n",
            "[epoch  3] [step 310] train_loss: 0.0497 train_acc: 0.9375 val_loss: 0.1470 val_acc: 0.8206\n",
            "[epoch  3] [step 320] train_loss: 0.0607 train_acc: 0.9281 val_loss: 0.1452 val_acc: 0.8198\n",
            "[epoch  3] [step 330] train_loss: 0.0644 train_acc: 0.9313 val_loss: 0.1519 val_acc: 0.8161\n",
            "[epoch  3] [step 340] train_loss: 0.0527 train_acc: 0.9281 val_loss: 0.1469 val_acc: 0.8236\n",
            "time: 484.4854s\n",
            "[epoch  4] [step  10] train_loss: 0.0415 train_acc: 0.9574 val_loss: 0.1614 val_acc: 0.8108\n",
            "[epoch  4] [step  20] train_loss: 0.0600 train_acc: 0.9281 val_loss: 0.1519 val_acc: 0.8198\n",
            "[epoch  4] [step  30] train_loss: 0.0393 train_acc: 0.9594 val_loss: 0.1485 val_acc: 0.8228\n",
            "[epoch  4] [step  40] train_loss: 0.0484 train_acc: 0.9406 val_loss: 0.1602 val_acc: 0.8101\n",
            "[epoch  4] [step  50] train_loss: 0.0413 train_acc: 0.9563 val_loss: 0.1573 val_acc: 0.8131\n",
            "[epoch  4] [step  60] train_loss: 0.0429 train_acc: 0.9469 val_loss: 0.1608 val_acc: 0.8138\n",
            "[epoch  4] [step  70] train_loss: 0.0397 train_acc: 0.9563 val_loss: 0.1647 val_acc: 0.8131\n",
            "[epoch  4] [step  80] train_loss: 0.0485 train_acc: 0.9406 val_loss: 0.1571 val_acc: 0.8161\n",
            "[epoch  4] [step  90] train_loss: 0.0484 train_acc: 0.9406 val_loss: 0.1505 val_acc: 0.8213\n",
            "[epoch  4] [step 100] train_loss: 0.0394 train_acc: 0.9594 val_loss: 0.1591 val_acc: 0.8153\n",
            "[epoch  4] [step 110] train_loss: 0.0424 train_acc: 0.9500 val_loss: 0.1638 val_acc: 0.8093\n",
            "[epoch  4] [step 120] train_loss: 0.0356 train_acc: 0.9500 val_loss: 0.1524 val_acc: 0.8198\n",
            "[epoch  4] [step 130] train_loss: 0.0491 train_acc: 0.9406 val_loss: 0.1570 val_acc: 0.8198\n",
            "[epoch  4] [step 140] train_loss: 0.0446 train_acc: 0.9437 val_loss: 0.1685 val_acc: 0.8056\n",
            "[epoch  4] [step 150] train_loss: 0.0467 train_acc: 0.9437 val_loss: 0.1524 val_acc: 0.8221\n",
            "[epoch  4] [step 160] train_loss: 0.0329 train_acc: 0.9656 val_loss: 0.1536 val_acc: 0.8236\n",
            "[epoch  4] [step 170] train_loss: 0.0409 train_acc: 0.9500 val_loss: 0.1529 val_acc: 0.8243\n",
            "[epoch  4] [step 180] train_loss: 0.0340 train_acc: 0.9625 val_loss: 0.1541 val_acc: 0.8176\n",
            "[epoch  4] [step 190] train_loss: 0.0482 train_acc: 0.9437 val_loss: 0.1553 val_acc: 0.8183\n",
            "[epoch  4] [step 200] train_loss: 0.0324 train_acc: 0.9625 val_loss: 0.1557 val_acc: 0.8191\n",
            "[epoch  4] [step 210] train_loss: 0.0550 train_acc: 0.9437 val_loss: 0.1567 val_acc: 0.8146\n",
            "[epoch  4] [step 220] train_loss: 0.0363 train_acc: 0.9531 val_loss: 0.1602 val_acc: 0.8138\n",
            "[epoch  4] [step 230] train_loss: 0.0425 train_acc: 0.9437 val_loss: 0.1741 val_acc: 0.8018\n",
            "[epoch  4] [step 240] train_loss: 0.0398 train_acc: 0.9531 val_loss: 0.1613 val_acc: 0.8093\n",
            "[epoch  4] [step 250] train_loss: 0.0621 train_acc: 0.9187 val_loss: 0.1743 val_acc: 0.8018\n",
            "[epoch  4] [step 260] train_loss: 0.0558 train_acc: 0.9344 val_loss: 0.1607 val_acc: 0.8056\n",
            "[epoch  4] [step 270] train_loss: 0.0538 train_acc: 0.9344 val_loss: 0.1568 val_acc: 0.8101\n",
            "[epoch  4] [step 280] train_loss: 0.0361 train_acc: 0.9594 val_loss: 0.1660 val_acc: 0.8078\n",
            "[epoch  4] [step 290] train_loss: 0.0618 train_acc: 0.9375 val_loss: 0.1576 val_acc: 0.8138\n",
            "[epoch  4] [step 300] train_loss: 0.0347 train_acc: 0.9625 val_loss: 0.1550 val_acc: 0.8176\n",
            "[epoch  4] [step 310] train_loss: 0.0390 train_acc: 0.9500 val_loss: 0.1608 val_acc: 0.8161\n",
            "[epoch  4] [step 320] train_loss: 0.0435 train_acc: 0.9437 val_loss: 0.1618 val_acc: 0.8123\n",
            "[epoch  4] [step 330] train_loss: 0.0473 train_acc: 0.9406 val_loss: 0.1567 val_acc: 0.8191\n",
            "[epoch  4] [step 340] train_loss: 0.0567 train_acc: 0.9313 val_loss: 0.1481 val_acc: 0.8243\n",
            "time: 482.4919s\n",
            "max_val_accuracy: 0.8363363363363363\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('CS4248-project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "acc163ef47be86fb239cdb7a5b440891b3a074f9418fa7049e8ce9b17a74f46c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}